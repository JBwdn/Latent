{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import Bioneural as bn\n",
    "import sys,getopt\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# load config\n",
    "def read_info():\n",
    "    data=[]\n",
    "    chem=[]\n",
    "    seq=[]\n",
    "    combined=[]\n",
    "    for line in open(\"Config.txt\",\"r\"): \n",
    "        data.append(line)\n",
    "    for i in data:\n",
    "        if re.match('MolecularStructuresNeuralNetworks:',i):\n",
    "            info=np.squeeze(re.findall('MolecularStructuresNeuralNetworks:(\\w*),\\[(.*)\\],(.*),(.*),(.*),(.*),(.*)',i))\n",
    "            number=re.split(r',',info[1])\n",
    "            number=[int(i) for i in number]\n",
    "            chem = {'Type' : info[0], 'Neuron' : number,'Optimizer' : info[2], 'InitializationMethod' : info[3],'Output_type':info[4] ,'Batch_size':int(info[5]),'Epoch':int(info[6])}\n",
    "        elif re.match('AminoAcidSequencesNeuralNetworks:',i):\n",
    "            info=np.squeeze(re.findall('AminoAcidSequencesNeuralNetworks:(\\w*),\\[(.*)\\],(.*),(.*),(.*),(.*),(.*),(.*)',i))\n",
    "            number=re.split(r',',info[1])\n",
    "            number=[int(i) for i in number]\n",
    "            seq = {'Type' : info[0], 'Neuron' : number,'Optimizer' : info[2], 'InitializationMethod' : info[3],'Dropout_rate':float(info[4]),'Output_type':info[5],'Batch_size':int(info[6]),'Epoch':int(info[7])}\n",
    "        elif re.match('CombinedNeuralNetworks:',i):\n",
    "            \n",
    "            info=np.squeeze(re.findall('CombinedNeuralNetworks:\\[(.*)\\],(.*),(.*),(.*),(.*)',i))\n",
    "            number=re.split(r',',info[0])\n",
    "            number=[int(i) for i in number]\n",
    "            combined = { 'Neuron' :number,'Optimizer' : info[1], 'InitializationMethod' : info[2],'Batch_size':int(info[3]),'Epoch':int(info[4])}\n",
    "    return chem,seq,combined\n",
    "\n",
    "# load linux shell parameters\n",
    "def get_para():\n",
    "    opts,args = getopt.getopt(sys.argv[1:], \"i:o:s:t:\")\n",
    "    input_file=\"\"\n",
    "    output_file=\"\"\n",
    "    input_file_solubility=\"\"\n",
    "    input_file_thermostability=\"\"\n",
    "    for op, value in opts:\n",
    "        if op == \"-i\":\n",
    "            input_file = value\n",
    "        elif op == \"-s\":\n",
    "            input_file_solubility = value\n",
    "        elif op == \"-t\":\n",
    "            input_file_thermostability = value\n",
    "        elif op == \"-o\":\n",
    "            output_file = value\n",
    "            #path=set_path(output_file)\n",
    "        elif op == \"-h\":\n",
    "            usage()\n",
    "            sys.exit()\n",
    "    return input_file,output_file,input_file_solubility,input_file_thermostability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency is: Counter({'L': 89702, 'A': 73834, 'E': 61872, 'R': 57930, 'V': 56902, 'G': 55558, 'S': 51514, 'I': 47854, 'D': 45246, 'T': 42578, 'Q': 38524, 'K': 37728, 'P': 36804, 'F': 31266, 'N': 29856, 'Y': 26454, 'H': 24564, 'M': 20344, 'W': 10678, 'C': 9980, 'X': 12})\n",
      "Amino acids type is: 21\n",
      "They are: dict_keys(['M', 'V', 'I', 'S', 'Q', 'L', 'T', 'K', 'E', 'G', 'R', 'Y', 'D', 'P', 'H', 'F', 'A', 'N', 'W', 'C', 'X'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\seaborn\\categorical.py:1460: FutureWarning: remove_na is deprecated and is a private function. Do not use.\n",
      "  stat_data = remove_na(group_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original vector shape:\n",
      "(2552, 1024, 4)\n",
      "The flattened vector shape:\n",
      " (2552, 4096)\n",
      "There are 1276 soluble chemicals (positive samples) and 1276 insoluble chemicals (negative samples).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAy8AAAJ8CAYAAAD3QJ7dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA08AAAJ4CAYAAAC9Nti7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSMyj/EjZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1008x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original vector shape:\n",
      "(1144, 1024, 4)\n",
      "The flattened vector shape:\n",
      " (1144, 4096)\n",
      "There are 587 soluble chemicals (positive samples) and 557 insoluble chemicals (negative samples).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of the seq length is: 1408.0\n",
      "The S.D. of the seq length is: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\seaborn\\distributions.py:214: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  color=hist_color, **hist_kws)\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\nonparametric\\kde.py:494: RuntimeWarning: invalid value encountered in true_divide\n",
      "  binned = fast_linbin(X,a,b,gridsize)/(delta*nobs)\n",
      "D:\\Anaconda\\lib\\site-packages\\statsmodels\\nonparametric\\kdetools.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  FAC1 = 2*(np.pi*bw/RANGE)**2\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:83: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Main\"\"\"\n",
    "path=bn.set_path(\"./result\")\n",
    "\n",
    "# python Biosensor_NN_Transfer_Learning.py -i biosensor_seqs.csv -o F:/result/ -s delaney.csv\n",
    "\"\"\"Load Data\"\"\"\n",
    "chem,seq,combined=read_info()\n",
    "cv=bn.load_biosensor(\"biosensor_seqs.csv\",\".\")\n",
    "#Load processed biosensor data\n",
    "Train_seq,Train_chemical,Label,d_to_index=bn.load_processed_biosensor(cv,\"biosensor_seqs.csv\",\".\")\n",
    "X_chem,Y_chem_hardmax=bn.load_solubility(\"delaney.csv\",\"./result\")\n",
    "bn.visu_KDE(Train_seq,\"seq length\",path+'Density Plot of seqs length.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate vocab for BERT\n",
    "from collections import Counter\n",
    "tmp=\"\"\n",
    "for i in cv.seq:\n",
    "    tmp = tmp + str(i)\n",
    "c2 = Counter(tmp)\n",
    "keys=\"\"\n",
    "for i in c2.keys():\n",
    "    keys=keys+str(i)\n",
    "keys=\"[UNK][CLS][SEP][MASK]\" + keys\n",
    "f2 = open('vocab.txt','r+')\n",
    "f2.write(keys)\n",
    "f2.close()\n",
    "\"\"\"WRITE CONTEXT\"\"\"\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "unpad=[]\n",
    "for i in list(cv.seq):\n",
    "    unpad.append(list(i))\n",
    "pad=pad_sequences(unpad, maxlen=256, dtype='object',padding='pre', truncating='pre', value=0.)\n",
    "for p,i in enumerate(pad):\n",
    "    for q,j in enumerate(i):\n",
    "        if j ==0.0:\n",
    "            pad[p][q]=\"0\"\n",
    "#context\n",
    "padded=[]\n",
    "for i in pad:\n",
    "    tex=\"\"\n",
    "    for j in i: \n",
    "        tex=tex+str(j)\n",
    "    padded.append(tex)\n",
    "\n",
    "f=open(\"cortext.txt\",'w')\n",
    "#f.write(str(list))\n",
    "for i in padded:\n",
    "    f.write(str(i)+'\\r\\n')  #\\r\\n\n",
    "f.close()\n",
    "\"\"\"Pre-training\"\"\"\n",
    "#  max_seq_length * masked_lm_prob 30\n",
    "! python ./bert/create_pretraining_data.py \\ --input_file=./cortext.txt \\ --output_file=./result/pretrained_model.tfrecord \\ --vocab_file=./vocab.txt \\ --do_lower_case=True \\ --max_seq_length=256 \\ --max_predictions_per_seq=38 \\  --masked_lm_prob=0.15 \\ --random_seed=12345 \\ --dupe_factor=5\n",
    "! python ./bert/run_pretraining.py \\ --input_file=./result/pretrained_model.tfrecord \\ --output_dir=./result/pretraining_output \\ --do_train=True \\ --do_eval=True \\ --train_batch_size=16 \\ --max_seq_length=256 \\ --max_predictions_per_seq=38 \\  --num_train_steps=600 \\ --num_warmup_steps=10 \\ --learning_rate=2e-5 \\ --bert_config_file=./bert_config.json\n",
    "! python ./bert/extract_features.py \\ --input_file=./cortext.txt \\ --output_file=./result/output.jsonl \\ --vocab_file=./vocab.txt \\ --bert_config_file=./result/bert_config.json \\ --init_checkpoint=./result/model.ckpt \\ --layers=-1,-2,-3,-4 \\ --max_seq_length=256 \\ --batch_size=16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "embedded=[]\n",
    "layers = []\n",
    "# load json and create embedding vectors\n",
    "with  open('./result/output.jsonl', 'r') as json_file:\n",
    "    for line in json_file:\n",
    "        for k in json.loads(line)['features'][0]['layers']:\n",
    "            layers.append(k['values'])\n",
    "        embedded.append(np.transpose(layers))\n",
    "        layers=[]\n",
    "json_file.close()\n",
    "cv.seq=embedded\n",
    "Train_seq=np.array(list(cv.seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "import pandas as pd \n",
    "from keras.layers import Bidirectional\n",
    "from keras.utils import plot_model\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from synbioTools import tensorChem\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.models import clone_model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import LSTM\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from Bio import SeqIO\n",
    "from Bio.PDB.Polypeptide import d1_to_index\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "\"\"\" Import_packages\"\"\"\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from IPython.display import SVG\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import csv\n",
    "from synbioTools import tensorChem\n",
    "\n",
    "## Load Data\n",
    "\n",
    "\"\"\" Read csv file and return it as a panda dataframe(dictionary) by biopython \"\"\"\n",
    "def readfasta(ffile):\n",
    "    \"\"\" Read fasta file, return dictionary \"\"\"\n",
    "    record_iterator = SeqIO.parse(ffile, \"fasta\")\n",
    "    a=pd.DataFrame(columns=['id','seq'])\n",
    "    for i in record_iterator:\n",
    "        a.loc[a.shape[0]+1] = [i.id,str(i.seq[:])] \n",
    "    return a\n",
    "\n",
    "\"\"\" Read csv file and return it as a panda dataframe(dictionary) \"\"\"\n",
    "def read_csv(path):\n",
    "    \"\"\" Read csv, return a panda dataframe(dictionary) \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    return df\n",
    "\n",
    "\"\"\"Load chemicals information and convert the chemical info to SMILES format \"\"\"\n",
    "def load_chemicals(properties=\"Solubility\",path=\"\",input_values=None):\n",
    "    if properties == \"Solubility\":\n",
    "        SolubilityData = read_csv(path) # read csv\n",
    "        chems=[] # variable to store the \n",
    "\n",
    "    #     # change column names of \n",
    "    #     SolubilityData.rename(columns={ SolubilityData.columns[1]: properties }, inplace=True)\n",
    "    #     SolubilityData.rename(columns={ SolubilityData.columns[0]: \"Compound\" }, inplace=True)\n",
    "    #     SolubilityData.rename(columns={ SolubilityData.columns[2]: \"SMILES\" }, inplace=True)\n",
    "\n",
    "        for row in range(0,len(SolubilityData['SMILES'])):\n",
    "            chems.append( Chem.MolFromSmiles(SolubilityData['SMILES'][row] ) )\n",
    "        SolubilityData['SMILES'] = chems\n",
    "        return SolubilityData # return the data list which contains the three input    \n",
    "    else:\n",
    "        chems=[] # variable to store the\n",
    "        for i in  input_values:\n",
    "            chems.append( Chem.MolFromInchi(i) )\n",
    "        return chems\n",
    "\n",
    "\n",
    "\"\"\" Visualize seq length and solu \"\"\"\n",
    "# plot the histogram of solubility\n",
    "import re\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "def visu_KDE(Values,name,path):\n",
    "    \n",
    "    if re.search(r'length',str(name)):\n",
    "        length=[]\n",
    "        for i in Values:\n",
    "            length.append(len(i))\n",
    "        train_y_plot = pd.Series( np.squeeze(length), name=name)\n",
    "    else:\n",
    "        train_y_plot = pd.Series( np.squeeze(Values), name=name)\n",
    "    mean = train_y_plot.mean()\n",
    "    std = train_y_plot.std()\n",
    "    print(\"The mean of the \"+name+\" is: \" + str(mean))\n",
    "    print(\"The S.D. of the \"+name+\" is: \" + str(std))\n",
    "    f,ax= plt.subplots(figsize = (14, 10))\n",
    "    sns.distplot(train_y_plot, kde=True, rug=True, hist=True)\n",
    "    ax.set_title(\"Density Plot of \"+name, fontsize=18, position=(0.5,1.05))\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "\n",
    "from collections import Counter\n",
    "\"\"\"Visualize seq vocab\"\"\"\n",
    "# Count amino acid and convert to vocab\n",
    "def vis_seq_elements(X_seq,path):\n",
    "    tmp=\"\"\n",
    "    for i in X_seq:\n",
    "        tmp = tmp + str(i)\n",
    "    c2 = Counter(tmp)\n",
    "    print(\"The frequency is: \" + str(c2))\n",
    "    print(\"Amino acids type is: \" + str(len(c2)))\n",
    "    print(\"They are: \" + str(c2.keys()))\n",
    "    k = pd.DataFrame.from_dict([c2])\n",
    "    classes=len(c2.keys())\n",
    "\n",
    "    f,ax= plt.subplots(figsize = (14, 10))\n",
    "    g=sns.barplot(data=k,ax=ax)\n",
    "    for p in g.patches:\n",
    "            g.annotate(\"%.0f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()), ha='center', va='center', rotation=0, xytext=(0, 20), textcoords='offset points')\n",
    "    ax.set_title(\"Frequencies Hist of Amino Acids\", fontsize=18, position=(0.5,1.05))\n",
    "    plt.savefig(path, bbox_inches='tight')\n",
    "    return list(c2.keys())\n",
    "\n",
    "## Tokenization\n",
    "\n",
    "\"\"\"Convert SMILES into fingerprint\"\"\"\n",
    "def chemFP(chem, FINGERPRINT_SIZE, MIN_PATH=1, MAX_PATH=5):\n",
    "    fpix = AllChem.RDKFingerprint(chem, minPath=MIN_PATH, maxPath=MAX_PATH, fpSize=FINGERPRINT_SIZE)    \n",
    "    fpix = [int(x) for x in list(fpix.ToBitString())]\n",
    "    return fpix\n",
    "\n",
    "\"\"\" Encode a chemical as a tensor by concatenating fingerprints up to desired depth \"\"\"\n",
    "def tensorChem(chems, FINGERPRINT_SIZE, CHEMDEPTH):\n",
    "    TRAIN_BATCH_SIZE = len(chems)   \n",
    "    Xs = np.zeros( (TRAIN_BATCH_SIZE, FINGERPRINT_SIZE, CHEMDEPTH) )\n",
    "    # print(Xs.shape)\n",
    "    for i in range(0, len(chems)-1):\n",
    "        for k in range(0, CHEMDEPTH):\n",
    "            fpix = chemFP(chems[i],FINGERPRINT_SIZE, k+1, k+1)\n",
    "            Xs[i, :, k] = fpix\n",
    "    return Xs\n",
    "\n",
    "\"\"\" Flatten the tensor into a two dimentional vector(feature mapping) \"\"\"\n",
    "# The original vector shape\n",
    "def flatten_chem(X_chem):\n",
    "    \n",
    "    depth = 4\n",
    "    fpSize = 1024\n",
    "    tc = tensorChem(X_chem,fpSize, depth)\n",
    "    print('The original vector shape:\\n'+str(tc.shape))\n",
    "    # The flattened vector shape\n",
    "    train_x_flatten = tc.reshape(tc.shape[0], -1)\n",
    "    print('The flattened vector shape:\\n '+str(train_x_flatten.shape))\n",
    "    return train_x_flatten\n",
    "\n",
    "def one_hot(seq):\n",
    "    \"\"\" Convert amino acid to one-hot vector stack \"\"\"\n",
    "    # Generate amino acids one-hot dict\n",
    "    to_one_hot = dict()\n",
    "    for i, a in enumerate(d1_to_index):\n",
    "        v = np.zeros(len(d1_to_index))\n",
    "        v[i] = 1\n",
    "        to_one_hot[a] = v\n",
    "    ix = []\n",
    "    result = []\n",
    "    # Tranfer the seq by the dict\n",
    "    for m in seq:\n",
    "        result.append(to_one_hot[m])\n",
    "    result = np.array(result)\n",
    "    return np.reshape(result, (1, result.shape[0], result.shape[1]))\n",
    "\n",
    "def index_seq(seq,vocab):\n",
    "    \"\"\" Convert amino acid to numerical index \"\"\"\n",
    "    index=[]\n",
    "    for i in seq:\n",
    "        if i in vocab: \n",
    "            p=vocab.index(i)\n",
    "            index.append(p)\n",
    "        else:\n",
    "            index.append('?')\n",
    "    index = index\n",
    "    return index\n",
    "\n",
    "def tensor_pad(seqs,vocab,max_length=False):\n",
    "    # Init seqs vector\n",
    "    seqs_index=[]\n",
    "    # Transfer seqs into index vector\n",
    "    for seq in seqs:\n",
    "        seqs_index.append(index_seq(seq,vocab))\n",
    "    # Pad the seqs\n",
    "    if max_length==False:\n",
    "        pad=pad_sequences(seqs_index, maxlen=None, dtype='int32',padding='pre', truncating='pre', value=0.)\n",
    "    else:\n",
    "        pad=pad_sequences(seqs_index, maxlen=max_length, dtype='int32',padding='pre', truncating='pre', value=0.)\n",
    "#     # one-hot encode the pad\n",
    "#     encoded = to_categorical(pad)\n",
    "\n",
    "    #return seqs_index\n",
    "    return pad\n",
    "\n",
    "\"\"\"Class to seq\"\"\"\n",
    "def catagorite_EC(EC):\n",
    "    tmp=[]\n",
    "    for i in EC:\n",
    "        i=i.split('.')\n",
    "        for k, a in enumerate(i):\n",
    "            if re.search(r'n',a):\n",
    "                a=re.search(r'\\d',a)[0]\n",
    "            i[k]=int(a)\n",
    "        if len(i)<=3:\n",
    "            i.append(0)\n",
    "        tmp.append(i)\n",
    "    return tmp\n",
    "\n",
    "\"\"\"Class to index\"\"\"\n",
    "from sklearn import preprocessing\n",
    "def catagorite_EC_index(EC):\n",
    "    encoder = preprocessing.LabelEncoder()\n",
    "    encoder.fit(EC)\n",
    "    EC = encoder.transform(EC)\n",
    "    num_classes = np.max(EC) + 1\n",
    "\n",
    "    # Convert labels to one hot\n",
    "    EC = to_categorical(EC, num_classes)\n",
    "    return EC\n",
    "\n",
    "def set_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return path\n",
    "\n",
    "\"\"\" Hardmax the labels \"\"\"\n",
    "# convert train_y into a vector range from 0 to 1\n",
    "def hardmax(Y_b4):\n",
    "    Y_b4=np.array([int(i) for i in Y_b4.T])\n",
    "    Y=np.zeros((1,len(Y_b4)))\n",
    "    mean = Y_b4.mean()\n",
    "    std = Y_b4.std()\n",
    "    for i in range(0,len(Y_b4)-1):\n",
    "        if (Y_b4[i] >=mean):\n",
    "            Y[0][i]=1\n",
    "        else:\n",
    "            Y[0][i]=0\n",
    "\n",
    "    print('There are '+ str(list(np.squeeze(Y)).count(1)) + ' soluble chemicals (positive samples) and ' + str(list(np.squeeze(Y)).count(0)) + ' insoluble chemicals (negative samples).')\n",
    "\n",
    "    # plot the input fingerprint length distribution plot\n",
    "    plt.plot(np.squeeze(Y))\n",
    "    plt.ylabel('solubility')\n",
    "    plt.xlabel('fingerprints')\n",
    "    plt.title(\"fingerprint and solubility distribution in binary classification\" )\n",
    "    plt.show()\n",
    "    \n",
    "    return np.squeeze(Y)\n",
    "\n",
    "## NN Architecture\n",
    "\n",
    "\"\"\"NN Model\"\"\"\n",
    "from keras import backend as K\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "\n",
    "# Customized R2 ACC method\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()))\n",
    "            \n",
    "#Try Adam as optimizer and implement time-based learning rate decay lr *= (1. / (1. + self.decay * self.iterations)\n",
    "         \n",
    "def create_network(layer_type=(\"LSTM\",[4096,32,32,1]),outputlayer_type='linear_regression',optimizer='Adam',Init='he_init',vocab=d1_to_index,drop_out=0.5):\n",
    "    # Setup hyperparameters for optimizers\n",
    "    Adam = optimizers.Adam(lr=0.0075, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-6, amsgrad=False)\n",
    "    sgd=optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "    \n",
    "    \n",
    "    # Start neural network\n",
    "    network = Sequential()\n",
    "    if layer_type[0]==\"LSTM\":\n",
    "#         network.add(LSTM(32, return_sequences=True, activation='relu',kernel_initializer='he_normal',bias_initializer='zeros'))\n",
    "#        network.add(Embedding(output_dim=layer_type[1][1], input_dim=len(vocab), input_length=(layer_type[1][0]),embeddings_initializer='uniform'))\n",
    "        for i in layer_type[1][2:-1]: \n",
    "            network.add(LSTM(i, return_sequences=True, activation='relu',kernel_initializer='he_normal',bias_initializer='zeros'))  # returns a sequence of vectors of dimension 32\n",
    "#         network.add(LSTM(i, return_sequences=True, activation='relu',kernel_initializer='he_normal',bias_initializer='zeros'))  # returns a sequence of vectors of dimension 32\n",
    "            network.add(Dropout(drop_out))\n",
    "        #     network.add(LSTM(32))  # return a single vector of dimension 32\n",
    "        network.add(Flatten())\n",
    "    elif layer_type[0]==\"DFF\":\n",
    "        network.add(layers.Dense(units=layer_type[1][1], activation='relu', input_shape=(layer_type[1][0],),kernel_initializer='he_normal',bias_initializer='zeros'))\n",
    "        if len(layer_type[1])>=4:\n",
    "            for i in layer_type[1][2:-1]:\n",
    "                # Add fully connected layer with a ReLU activation function\n",
    "                network.add(layers.Dense(units=i, activation='relu'))\n",
    "\n",
    "    if outputlayer_type=='linear_regression':\n",
    "        if layer_type[1][-1]!=0:\n",
    "\n",
    "        # Add fully connected layer with a sigmoid activation function\n",
    "            network.add(layers.Dense(units=layer_type[1][-1]))\n",
    "\n",
    "            # Compile neural network\n",
    "            if optimizer == 'bgd':\n",
    "                network.compile(loss='mean_squared_error',optimizer= sgd,metrics=[coeff_determination]) # Accuracy performance metric-R2 sgd\n",
    "                print(\"Optimizer batch gradient decent; Loss mean_squared_error.\")\n",
    "            elif optimizer == 'Adam':\n",
    "                network.compile(loss='mean_squared_error',optimizer= Adam,metrics=[coeff_determination]) # Accuracy performance metric-R2 Adam\n",
    "                print(\"Optimizer Adam; Loss mean_squared_error.\")\n",
    "            \n",
    "    elif outputlayer_type=='binary_classifier':\n",
    "        if layer_type[1][-1]!=0:\n",
    "        # Add fully connected layer with a sigmoid activation function\n",
    "            network.add(layers.Dense(units=layer_type[1][-1], activation='sigmoid'))\n",
    "\n",
    "            # Compile neural network\n",
    "            if optimizer == 'sgd':\n",
    "                network.compile(loss='binary_crossentropy',optimizer= sgd,metrics=['accuracy']) # Accuracy performance metric sgd\n",
    "                print(\"Optimizer batch gradient decent; binary_crossentropy.\")\n",
    "            elif optimizer == 'Adam':\n",
    "                network.compile(loss='binary_crossentropy',optimizer= Adam,metrics=['accuracy']) # Accuracy performance metric Adam\n",
    "                print(\"Optimizer Adam; binary_crossentropy.\")\n",
    "    \n",
    "    elif outputlayer_type=='multiple_classifier':\n",
    "        if layer_type[1][-1]!=0:\n",
    "        # Add fully connected layer with a softmax activation function\n",
    "            network.add(Dense(layer_type[1][-1], activation='softmax'))\n",
    "            # Compile neural network\n",
    "            if optimizer == 'bgd':\n",
    "                network.compile(loss='categorical_crossentropy',optimizer= sgd,metrics=['accuracy']) # Accuracy performance metric-R2 sgd\n",
    "                print(\"Optimizer batch gradient decent; Loss mean_squared_error.\")\n",
    "            elif optimizer == 'Adam':\n",
    "                network.compile(loss='categorical_crossentropy',optimizer= Adam,metrics=['accuracy']) # Accuracy performance metric-R2 Adam\n",
    "                print(\"Optimizer Adam; Loss mean_squared_error.\")\n",
    "    \n",
    "    # Return compiled network\n",
    "    return network\n",
    "\n",
    "def combine_models(Seq_NN,Seq_input,Chem_NN,Chem_input):\n",
    "    Seq_input = Input(shape=(Seq_input,4))\n",
    "    encoded_seq = Seq_NN(Seq_input)\n",
    "    Chem_input = Input(shape=(Chem_input,))\n",
    "    encoded_chem = Chem_NN(Chem_input)\n",
    "    merged_NN1 = layers.concatenate([encoded_seq, encoded_chem])\n",
    "    NN1=  layers.Dense(units=128, activation='relu',kernel_initializer='he_normal',bias_initializer='zeros')(merged_NN1)\n",
    "    NN2=  layers.Dense(units=128, activation='relu',kernel_initializer='he_normal',bias_initializer='zeros')(NN1)\n",
    "    NN3=  layers.Dense(units=128, activation='relu',kernel_initializer='he_normal',bias_initializer='zeros')(NN2)\n",
    "    merged_NN =  layers.Dense(units=1,activation='sigmoid')(NN3)\n",
    "    combined_model = Model([Seq_input, Chem_input], merged_NN)\n",
    "#     combined_model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
    "    return combined_model\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "def get_r2_numpy(x, y):\n",
    "    slope, intercept = np.polyfit(x, y, 1)\n",
    "    r_squared = 1 - (sum((y - (slope * x + intercept))**2) / ((len(y) - 1) * np.var(y, ddof=1)))\n",
    "    return r_squared\n",
    "\n",
    "def get_r2_scipy(x, y):\n",
    "    _, _, r_value, _, _ = stats.linregress(x, y)\n",
    "    return r_value**2\n",
    "\n",
    "def get_r2_statsmodels(x, y):\n",
    "    return sm.OLS(y, sm.add_constant(x)).fit().rsquared\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def confusion_heatmap(Y_seq_EC_tokenized_index,Y_pre_EC,name):\n",
    "\n",
    "    tmp=[]\n",
    "    for i in Y_pre_EC:\n",
    "        num = np.argmax(i)\n",
    "        tmp.append(num)\n",
    "    Y_re=[np.argmax(i) for i in Y_seq_EC_tokenized_index]\n",
    "    Y_re=np.array(Y_re).reshape(np.array(Y_re).shape[0],)\n",
    "    tmp=np.array(tmp)\n",
    "\n",
    "    table=pd.crosstab(Y_re,tmp, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    table.to_csv(name + \"error_map.csv\")\n",
    "\n",
    "    cnf_matrix = confusion_matrix(Y_re, tmp)\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=d2_to_index,title='Confusion matrix , without normalization')\n",
    "    plt.savefig(name + \"confusion_heatmap.svg\", bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Plot linear regression\n",
    "def linear_regression(Train_Y,Train_Y_pred,Test_Y,Test_Y_pred,path,i):\n",
    "        r_square=get_r2_statsmodels(Train_Y_pred,Train_Y)\n",
    "        q_square=get_r2_statsmodels(Test_Y_pred,Test_Y)\n",
    "        \n",
    "        # Plot Training-set\n",
    "        model=LinearRegression()\n",
    "        model.fit(Train_Y_pred,Train_Y)\n",
    "        ax=plt.gca()\n",
    "        plt.scatter(Train_Y_pred,Train_Y)\n",
    "        y_train_pred=model.predict(Train_Y_pred)\n",
    "        plt.title('Linear regression of solubility training prediction in fold '+str(i+1))\n",
    "        plt.text(0.5,0.7,\"The R-square value is %.2f \" % r_square, verticalalignment='bottom', horizontalalignment='right',transform=ax.transAxes)\n",
    "        plt.plot(Train_Y_pred,y_train_pred,color='black',linewidth=3,label=\"R-square\")\n",
    "        plt.legend(loc=2)\n",
    "        plt.xlabel(\"train  (mol/L)\")\n",
    "        plt.ylabel(\"theorical  (mol/L)\")\n",
    "\n",
    "        # Plot Testing-set\n",
    "        model=LinearRegression()\n",
    "        model.fit(Test_Y_pred,Test_Y)\n",
    "\n",
    "        plt.scatter(Test_Y_pred,Test_Y)\n",
    "        y_train_pred=model.predict(Test_Y_pred)\n",
    "\n",
    "        plt.text(0.5,0.645,\"The Q-square value is %.2f \" % q_square,verticalalignment='bottom',color='red', horizontalalignment='right',transform=ax.transAxes)\n",
    "        plt.plot(Test_Y_pred,y_train_pred,color='red',linewidth=3,label=\"Q-square\")\n",
    "        plt.legend(loc=2)\n",
    "        \n",
    "        plt.savefig(path+'linear_regression_fold_'+str(i+1)+'.svg', bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "# Linear regression INFO\n",
    "\n",
    "class error_ana_info():\n",
    "    def __init__(self):\n",
    "        self._train_metric = None\n",
    "        self._test_metric = None\n",
    "        self.df = None\n",
    "        self.mdif = None\n",
    "    \n",
    "    def add_info(self,train_metric,test_metric):\n",
    "        if self._train_metric is None or  self._test_metric is None:\n",
    "            self._train_metric = np.array(train_metric)\n",
    "            self._test_metric = np.array(test_metric)\n",
    "        else:\n",
    "            self._train_metric = np.vstack((self._train_metric, train_metric))\n",
    "            self._test_metric = np.vstack((self._test_metric, test_metric))\n",
    "    \n",
    "    def generate_csv(self,row_names,name):\n",
    "        if (self._train_metric.size!=0 and self._test_metric.size!=0):\n",
    "            _acc=[]\n",
    "            _acc_in_val_acc=[]\n",
    "            _valacc=[]\n",
    "            _epochs=[]\n",
    "            _train_err=[]\n",
    "\n",
    "            # Calculate max train_acc\n",
    "            for i in self._train_metric:\n",
    "                _acc.append(np.max(i))\n",
    "\n",
    "            # Calculate max test_acc and optimal_epo\n",
    "            for index,i in enumerate(self._test_metric):\n",
    "                _valacc.append(np.max(i))\n",
    "                _epochs.append(np.where(i==np.max(i,axis=0))[0][0]+1)\n",
    "                _acc_in_val_acc.append(self._train_metric[index][np.where(i==np.max(i,axis=0))[0][0]])\n",
    "            \n",
    "#            print(_acc,_acc_in_val_acc)\n",
    "            # Calculate max training_err\n",
    "            for i in range(len(_acc)):\n",
    "                _train_err.append('%.2f%%' %(((_acc[i]-_acc_in_val_acc[i])/_acc_in_val_acc[i])*100))\n",
    "                \n",
    "            self.df=[_acc,_acc_in_val_acc,_valacc,_epochs,_train_err]\n",
    "            self.df = pd.DataFrame(self.df)\n",
    "            self.df.set_index([row_names],inplace=True)\n",
    "            \n",
    "            # Calculate Average Value\n",
    "            meanv=[]\n",
    "            for index, row in self.df.iterrows():\n",
    "                \n",
    "                row=list(row)\n",
    "                if re.search(r'\\%',str(row[1])):\n",
    "                    row=[float(j.strip(\"%\")) for j in row]\n",
    "                    meanv.append(str(np.mean(row))+\"%\")\n",
    "                else:\n",
    "                    row=[float(j) for j in row]\n",
    "                    meanv.append(np.mean(list(row)))\n",
    "\n",
    "            self.df['B']=meanv\n",
    "            \n",
    "            col=[]\n",
    "            for i in range(1,len(self.df.iloc[0])):\n",
    "                col.append(\"Fold \"+str(i))\n",
    "            col.append('Average Value')\n",
    "            self.df.columns = col\n",
    "            self.df.to_csv(name)\n",
    "            \n",
    "    def generate_model_info(self,epochs,batch_size,initialization,bias,name):\n",
    "        Hyperparameters=pd.Series(data=['epochs','batch_size','initialization','bias'],name='Hyperparameters')\n",
    "        Settings=pd.Series(data=[epochs,batch_size,initialization,bias],name='Settings')\n",
    "        Settings.rename('Settings')\n",
    "        self.mdif=pd.DataFrame()\n",
    "        self.mdif= self.mdif.join(Hyperparameters, how='right')\n",
    "        self.mdif= self.mdif.join(Settings)\n",
    "        self.mdif.to_csv(name,index=False) \n",
    "\n",
    "# define the training visualization function\n",
    "def training_vis(hist,outputlayer,name):\n",
    "    loss = hist.history['loss']\n",
    "    val_loss = hist.history['val_loss']\n",
    "    if outputlayer=='linear_regression':\n",
    "        acc = hist.history['coeff_determination']\n",
    "        val_acc = hist.history['val_coeff_determination']\n",
    "    elif outputlayer=='binary_classifier':\n",
    "        acc = hist.history['acc']\n",
    "        val_acc = hist.history['val_acc']\n",
    "    elif outputlayer=='multiple_classifier':\n",
    "        acc = hist.history['acc']\n",
    "        val_acc = hist.history['val_acc']\n",
    "\n",
    "    # make a figure\n",
    "    fig = plt.figure(figsize=(8,4))\n",
    "    # subplot loss\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.plot(loss,label='train_loss')\n",
    "    ax1.plot(val_loss,label='val_loss')\n",
    "    ax1.set_xlabel('Epochs')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Loss on Training and Validation Data')\n",
    "    ax1.legend()\n",
    "    # subplot acc\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    if outputlayer=='linear_regression':\n",
    "        ax2.plot(acc,label='train_coeff_determination')\n",
    "        ax2.plot(val_acc,label='val_coeff_determination')\n",
    "        ax2.set_xlabel('Epochs')\n",
    "        ax2.set_ylabel('Coeff_determination')\n",
    "        ax2.set_title('Coeff_determination  on Training and Validation Data')\n",
    "    elif outputlayer=='binary_classifier':\n",
    "        ax2.plot(acc,label='train_accuracy')\n",
    "        ax2.plot(val_acc,label='val_accuracy')\n",
    "        ax2.set_xlabel('Epochs')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title('Accuracy  on Training and Validation Data')\n",
    "    elif outputlayer=='multiple_classifier':\n",
    "        ax2.plot(acc,label='train_accuracy')\n",
    "        ax2.plot(val_acc,label='val_accuracy')\n",
    "        ax2.set_xlabel('Epochs')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title('Accuracy  on Training and Validation Data')\n",
    "    \n",
    "    ax2.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(name, bbox_inches='tight')\n",
    "    plt. close()\n",
    "\n",
    "### \"\"\"StratifiedKFold\"\"\"\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import KFold \n",
    "from sklearn.linear_model import LinearRegression\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from keras.layers import Dropout\n",
    "\n",
    "def k_folds_NN(network=None, X=None, Y=None, batch_size=50, epochs=5, path='C:/Users/DR/Desktop/P2/Latent-master/pic/Seq_linear_regression_dropout_1138/', Init='he_init', outputlayer_type='binary_classifier',optimizer = 'Adam'):\n",
    "    # Store training info\n",
    "    info=error_ana_info()\n",
    "    \n",
    "    # Split the dataset in 3 folds\n",
    "    sfolder = KFold(n_splits=3,random_state=0,shuffle=True)\n",
    "    \n",
    "#     plot_model(network, to_file=path+'multilayer_perceptron_graph.png')\n",
    "    \n",
    "    if len(X)>=2:\n",
    "        sfolder.get_n_splits(X[0],Y)\n",
    "\n",
    "        # If directory dosn't exixst, then create directory.  \n",
    "        set_path(path)\n",
    "        \n",
    "        Network=[]\n",
    "        \n",
    "    #    early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=8,verbose=0, mode='auto')## Callback for early stopping the training\n",
    "        \n",
    "        #K-folds iteration    \n",
    "        for i, (train, test) in enumerate(sfolder.split(X[0],Y)):\n",
    "            X_train , X_test=[] , []\n",
    "            for j in X:\n",
    "                X_train, X_test = X_train + [j[train]], X_test + [j[test]]\n",
    "            y_train, y_test = Y[train], Y[test]\n",
    "            \n",
    "            Network.append(clone_model(network))\n",
    "            if outputlayer_type=='linear_regression':\n",
    "                if optimizer == 'bgd':\n",
    "                    Network[i].compile(loss='mean_squared_error',optimizer= sgd,metrics=[coeff_determination]) # Accuracy performance metric-R2 sgd\n",
    "                elif optimizer == 'Adam':\n",
    "                    Network[i].compile(loss='mean_squared_error',optimizer= Adam,metrics=[coeff_determination]) # Accuracy performance metric-R2 Adam\n",
    "            elif outputlayer_type=='binary_classifier':\n",
    "                if optimizer == 'sgd':\n",
    "                    Network[i].compile(loss='binary_crossentropy',optimizer= sgd,metrics=['accuracy']) # Accuracy performance metric sgd\n",
    "                elif optimizer == 'Adam':\n",
    "                    Network[i].compile(loss='binary_crossentropy',optimizer= Adam,metrics=['accuracy']) # Accuracy performance metric Adam\n",
    "            elif outputlayer_type=='multiple_classifier':\n",
    "                if optimizer == 'bgd':\n",
    "                    Network[i].compile(loss='categorical_crossentropy',optimizer= sgd,metrics=['accuracy']) # Accuracy performance metric-R2 sgd\n",
    "                elif optimizer == 'Adam':\n",
    "                    Network[i].compile(loss='categorical_crossentropy',optimizer= Adam,metrics=['accuracy']) # Accuracy performance metric-R2 Adam\n",
    "            \n",
    "            # Train the model with each combination of folds\n",
    "            hist = Network[i].fit(X_train, y_train,batch_size=batch_size, epochs=epochs, validation_data=(X_test,y_test))\n",
    "\n",
    "            if outputlayer_type=='linear_regression':\n",
    "                # Plot Linear Regression\n",
    "                info.add_info(hist.history['coeff_determination'],hist.history['val_coeff_determination'])\n",
    "                linear_regression(Train_Y=y_train,Train_Y_pred=Network[i].predict(X_train),Test_Y=y_test,Test_Y_pred=Network[i].predict(X_test),path=path,i=i)\n",
    "            elif outputlayer_type=='binary_classifier':\n",
    "                info.add_info(hist.history['acc'],hist.history['val_acc'])\n",
    "            elif outputlayer_type=='multiple_classifier':\n",
    "                info.add_info(hist.history['acc'],hist.history['val_acc'])\n",
    "                confusion_heatmap(y_test,Network[i].predict(X_test),path + \"fold_\" + str(i+1) + \"_\")\n",
    "\n",
    "        # hist = network.fit(X_train,  y_train,batch_size=batch_size, epochs=epochs, validation_data=(X_test,y_test), callbacks=[early_stopping])\n",
    "\n",
    "            # Plot runtime\n",
    "            training_vis(hist,outputlayer_type,path+\"train_fold \"+str(i+1)+\".svg\")\n",
    "\n",
    "            # Save NN Model\n",
    "            Network[i].save(path+'batch_size_'+str(batch_size)+'epochs_'+str(epochs)+'fold_'+str(i+1)+'.h5')\n",
    "            i=i+1\n",
    "    else:\n",
    "        X=np.squeeze(X)\n",
    "        sfolder.get_n_splits(X,Y)\n",
    "\n",
    "        # If directory dosn't exixst, then create directory.  \n",
    "        set_path(path)\n",
    "        \n",
    "        Network=[]\n",
    "        \n",
    "    #    early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=8,verbose=0, mode='auto')## Callback for early stopping the training\n",
    "\n",
    "        #K-folds iteration    \n",
    "        for i, (train, test) in enumerate(sfolder.split(X,Y)):\n",
    "            X_train, X_test = X[train], X[test]\n",
    "            y_train, y_test = Y[train], Y[test]\n",
    "\n",
    "            # Train the model with each combination of folds\n",
    "            Network.append(clone_model(network))\n",
    "            if outputlayer_type=='linear_regression':\n",
    "                if optimizer == 'bgd':\n",
    "                    Network[i].compile(loss='mean_squared_error',optimizer= sgd,metrics=[coeff_determination]) # Accuracy performance metric-R2 sgd\n",
    "                elif optimizer == 'Adam':\n",
    "                    Network[i].compile(loss='mean_squared_error',optimizer= Adam,metrics=[coeff_determination]) # Accuracy performance metric-R2 Adam\n",
    "            elif outputlayer_type=='binary_classifier':\n",
    "                if optimizer == 'sgd':\n",
    "                    Network[i].compile(loss='binary_crossentropy',optimizer= sgd,metrics=['accuracy']) # Accuracy performance metric sgd\n",
    "                elif optimizer == 'Adam':\n",
    "                    Network[i].compile(loss='binary_crossentropy',optimizer= Adam,metrics=['accuracy']) # Accuracy performance metric Adam\n",
    "            elif outputlayer_type=='multiple_classifier':\n",
    "                if optimizer == 'bgd':\n",
    "                    Network[i].compile(loss='categorical_crossentropy',optimizer= sgd,metrics=['accuracy']) # Accuracy performance metric-R2 sgd\n",
    "                elif optimizer == 'Adam':\n",
    "                    Network[i].compile(loss='categorical_crossentropy',optimizer= Adam,metrics=['accuracy']) # Accuracy performance metric-R2 Adam\n",
    "            \n",
    "            hist = Network[i].fit(X_train, y_train,batch_size=batch_size, epochs=epochs, validation_data=(X_test,y_test))\n",
    "\n",
    "            if outputlayer_type=='linear_regression':\n",
    "                # Plot Linear Regression\n",
    "                info.add_info(hist.history['coeff_determination'],hist.history['val_coeff_determination'])\n",
    "                linear_regression(Train_Y=y_train,Train_Y_pred=Network[i].predict(X_train),Test_Y=y_test,Test_Y_pred=Network[i].predict(X_test),path=path,i=i)\n",
    "            elif outputlayer_type=='binary_classifier':\n",
    "                info.add_info(hist.history['acc'],hist.history['val_acc'])\n",
    "            elif outputlayer_type=='multiple_classifier':\n",
    "                info.add_info(hist.history['acc'],hist.history['val_acc'])\n",
    "                confusion_heatmap(y_test,Network[i].predict(X_test),path + \"fold_\" + str(i+1) + \"_\")\n",
    "\n",
    "        # hist = network.fit(X_train,  y_train,batch_size=batch_size, epochs=epochs, validation_data=(X_test,y_test), callbacks=[early_stopping])\n",
    "\n",
    "            # Plot runtime\n",
    "            training_vis(hist,outputlayer_type,path+\"train_fold \"+str(i+1)+\".svg\")\n",
    "\n",
    "            # Save NN Model\n",
    "            Network[i].save(path+'batch_size_'+str(batch_size)+'epochs_'+str(epochs)+'fold_'+str(i+1)+'.h5')\n",
    "            i=i+1\n",
    "        \n",
    "    # Output training information\n",
    "    if outputlayer_type=='linear_regression':\n",
    "        info.generate_csv(['R2','R2_opt','Q2','Epochs_opt','Train_err'],path+\"training_result.csv\")\n",
    "    elif outputlayer_type=='binary_classifier':\n",
    "        info.generate_csv(['Train_Acc','Train_Acc_opt','Test_Acc','Epochs_opt','Train_err'],path+\"training_result.csv\")\n",
    "    elif outputlayer_type=='multiple_classifier':\n",
    "        info.generate_csv(['Train_Acc','Train_Acc_opt','Test_Acc','Epochs_opt','Train_err'],path+\"training_result.csv\")\n",
    "    \n",
    "    if Init=='he_init':\n",
    "        info.generate_model_info(epochs,batch_size,\"He_Init\",\"Enabled\",path+'model_info.csv')\n",
    "    elif Init=='random_no_bias':\n",
    "        info.generate_model_info(epochs,batch_size,\"Random\",\"False\",path+'model_info.csv')\n",
    "    elif Init=='random_with_bias':\n",
    "        info.generate_model_info(epochs,batch_size,\"Random\",\"True\",path+'model_info.csv')\n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "Seq_NN=create_network(layer_type=(\"LSTM\",[Train_seq.shape[1],32,32,0]),outputlayer_type='',optimizer='Adam',Init='he_init',vocab=d_to_index,drop_out=0.5)\n",
    "Chem_NN=create_network(layer_type=(\"DFF\",[Train_chemical.shape[1],32,0]),outputlayer_type='',optimizer='Adam',Init='he_init')\n",
    "combine_model = combine_models(Seq_NN,Train_seq.shape[1],Chem_NN,Train_chemical.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_20 (InputLayer)           (None, 32, 4)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_21 (InputLayer)           (None, 4096)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_33 (Sequential)      (None, 1024)         4736        input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sequential_34 (Sequential)      (None, 32)           131104      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 1056)         0           sequential_33[1][0]              \n",
      "                                                                 sequential_34[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          135296      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          16512       dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          16512       dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1)            129         dense_30[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 304,289\n",
      "Trainable params: 304,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combine_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1786 samples, validate on 766 samples\n",
      "Epoch 1/30\n",
      "1786/1786 [==============================] - 1s 762us/step - loss: 0.7967 - acc: 0.5011 - val_loss: 0.6937 - val_acc: 0.5039\n",
      "Epoch 2/30\n",
      "1786/1786 [==============================] - 0s 149us/step - loss: 0.7024 - acc: 0.5140 - val_loss: 0.6990 - val_acc: 0.5039\n",
      "Epoch 3/30\n",
      "1786/1786 [==============================] - 0s 147us/step - loss: 0.7145 - acc: 0.4776 - val_loss: 0.6937 - val_acc: 0.5000\n",
      "Epoch 4/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.7039 - acc: 0.4933 - val_loss: 0.6951 - val_acc: 0.4961\n",
      "Epoch 5/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.6998 - acc: 0.4989 - val_loss: 0.6990 - val_acc: 0.5039\n",
      "Epoch 6/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.7022 - acc: 0.4882 - val_loss: 0.6936 - val_acc: 0.4961\n",
      "Epoch 7/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.6991 - acc: 0.5095 - val_loss: 0.6965 - val_acc: 0.5039\n",
      "Epoch 8/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.7023 - acc: 0.4994 - val_loss: 0.6948 - val_acc: 0.5039\n",
      "Epoch 9/30\n",
      "1786/1786 [==============================] - 0s 145us/step - loss: 0.7004 - acc: 0.4838 - val_loss: 0.6943 - val_acc: 0.4961\n",
      "Epoch 10/30\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.6984 - acc: 0.4832 - val_loss: 0.6944 - val_acc: 0.4961\n",
      "Epoch 11/30\n",
      "1786/1786 [==============================] - 0s 147us/step - loss: 0.6961 - acc: 0.5129 - val_loss: 0.7009 - val_acc: 0.5039\n",
      "Epoch 12/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.6990 - acc: 0.4950 - val_loss: 0.6934 - val_acc: 0.5065\n",
      "Epoch 13/30\n",
      "1786/1786 [==============================] - 0s 147us/step - loss: 0.6984 - acc: 0.5028 - val_loss: 0.6933 - val_acc: 0.4948\n",
      "Epoch 14/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.6967 - acc: 0.5039 - val_loss: 0.6940 - val_acc: 0.4961\n",
      "Epoch 15/30\n",
      "1786/1786 [==============================] - 0s 147us/step - loss: 0.6947 - acc: 0.5045 - val_loss: 0.6982 - val_acc: 0.5039\n",
      "Epoch 16/30\n",
      "1786/1786 [==============================] - 0s 161us/step - loss: 0.6964 - acc: 0.5011 - val_loss: 0.6956 - val_acc: 0.4961\n",
      "Epoch 17/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.6999 - acc: 0.4938 - val_loss: 0.6937 - val_acc: 0.4987\n",
      "Epoch 18/30\n",
      "1786/1786 [==============================] - 0s 147us/step - loss: 0.6972 - acc: 0.5190 - val_loss: 0.7013 - val_acc: 0.5039\n",
      "Epoch 19/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.6980 - acc: 0.5034 - val_loss: 0.6935 - val_acc: 0.4961\n",
      "Epoch 20/30\n",
      "1786/1786 [==============================] - 0s 155us/step - loss: 0.6936 - acc: 0.5106 - val_loss: 0.6993 - val_acc: 0.5039\n",
      "Epoch 21/30\n",
      "1786/1786 [==============================] - 0s 162us/step - loss: 0.6963 - acc: 0.4888 - val_loss: 0.6938 - val_acc: 0.4856\n",
      "Epoch 22/30\n",
      "1786/1786 [==============================] - 0s 149us/step - loss: 0.6967 - acc: 0.4989 - val_loss: 0.6943 - val_acc: 0.4530\n",
      "Epoch 23/30\n",
      "1786/1786 [==============================] - 0s 149us/step - loss: 0.6960 - acc: 0.5006 - val_loss: 0.6951 - val_acc: 0.4883\n",
      "Epoch 24/30\n",
      "1786/1786 [==============================] - 0s 150us/step - loss: 0.6940 - acc: 0.4983 - val_loss: 0.6951 - val_acc: 0.4935\n",
      "Epoch 25/30\n",
      "1786/1786 [==============================] - 0s 147us/step - loss: 0.6933 - acc: 0.5146 - val_loss: 0.6962 - val_acc: 0.4909\n",
      "Epoch 26/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.6988 - acc: 0.4950 - val_loss: 0.7088 - val_acc: 0.4961\n",
      "Epoch 27/30\n",
      "1786/1786 [==============================] - 0s 146us/step - loss: 0.6990 - acc: 0.4888 - val_loss: 0.6958 - val_acc: 0.4961\n",
      "Epoch 28/30\n",
      "1786/1786 [==============================] - 0s 147us/step - loss: 0.6954 - acc: 0.4888 - val_loss: 0.6938 - val_acc: 0.4961\n",
      "Epoch 29/30\n",
      "1786/1786 [==============================] - 0s 147us/step - loss: 0.6952 - acc: 0.4787 - val_loss: 0.6935 - val_acc: 0.4765\n",
      "Epoch 30/30\n",
      "1786/1786 [==============================] - 0s 149us/step - loss: 0.6950 - acc: 0.4994 - val_loss: 0.6931 - val_acc: 0.5000\n"
     ]
    }
   ],
   "source": [
    "combine_model.compile(loss='binary_crossentropy',optimizer= 'Adam',metrics=['accuracy'])\n",
    "c_m=combine_model.fit([Train_seq]+[Train_chemical],Label,batch_size=128, epochs=30,validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pickle\n",
    "import bert\n",
    "from bert import run_classifier\n",
    "from bert import optimization\n",
    "from bert import tokenization\n",
    "\n",
    "##\n",
    "def pretty_print(result):\n",
    "    df = pd.DataFrame([result]).T\n",
    "    df.columns = [\"values\"]\n",
    "    return df\n",
    "\n",
    "def create_tokenizer_from_hub_module(bert_model_hub):\n",
    "\n",
    "    with tf.Graph().as_default():\n",
    "        bert_module = hub.Module(bert_model_hub)\n",
    "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    with tf.Session() as sess:\n",
    "        vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
    "                                            tokenization_info[\"do_lower_case\"]])\n",
    "      \n",
    "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def make_features(dataset, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN):\n",
    "    input_example = dataset.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
    "                                                                   text_a = x[DATA_COLUMN], \n",
    "                                                                   text_b = None, \n",
    "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
    "    features = bert.run_classifier.convert_examples_to_features(input_example, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
    "    return features\n",
    "\n",
    "def create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, labels,num_labels):\n",
    "    bert_module = hub.Module(bert_model_hub,trainable=True)\n",
    "    bert_inputs = dict(input_ids=input_ids,input_mask=input_mask,segment_ids=segment_ids)\n",
    "    bert_outputs = bert_module(inputs=bert_inputs,signature=\"tokens\",as_dict=True)\n",
    "\n",
    "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
    "    # Use \"sequence_outputs\" for token-level output.\n",
    "    output_layer = bert_outputs[\"pooled_output\"]\n",
    "\n",
    "    hidden_size = output_layer.shape[-1].value\n",
    "\n",
    "  # Create our own layer to tune for politeness data.\n",
    "    output_weights = tf.get_variable(\"output_weights\", [num_labels, hidden_size],initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "    output_bias = tf.get_variable(\"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"loss\"):\n",
    "\n",
    "        # Dropout helps prevent overfitting\n",
    "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
    "\n",
    "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
    "        logits = tf.nn.bias_add(logits, output_bias)\n",
    "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
    "\n",
    "        # Convert labels into one-hot encoding\n",
    "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
    "\n",
    "        predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
    "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
    "        if is_predicting:\n",
    "            return (predicted_labels, log_probs)\n",
    "\n",
    "        # If we're train/eval, compute loss between predicted and actual label\n",
    "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
    "        loss = tf.reduce_mean(per_example_loss)\n",
    "        return (loss, predicted_labels, log_probs)\n",
    "\n",
    "# model_fn_builder actually creates our model function\n",
    "# using the passed parameters for num_labels, learning_rate, etc.\n",
    "def model_fn_builder(bert_model_hub, num_labels, learning_rate, num_train_steps,num_warmup_steps):\n",
    " \n",
    "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
    "        input_ids = features[\"input_ids\"]\n",
    "        input_mask = features[\"input_mask\"]\n",
    "        segment_ids = features[\"segment_ids\"]\n",
    "        label_ids = features[\"label_ids\"]\n",
    "\n",
    "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
    "\n",
    "        # TRAIN and EVAL\n",
    "        if not is_predicting:\n",
    "            (loss, predicted_labels, log_probs) = create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "            train_op = bert.optimization.create_optimizer(loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
    "\n",
    "          # Calculate evaluation metrics. \n",
    "            def metric_fn(label_ids, predicted_labels):\n",
    "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
    "                f1_score = tf.contrib.metrics.f1_score(label_ids,predicted_labels)\n",
    "                auc = tf.metrics.auc(label_ids,predicted_labels)\n",
    "                recall = tf.metrics.recall(label_ids,predicted_labels)\n",
    "                precision = tf.metrics.precision(label_ids,predicted_labels) \n",
    "                true_pos = tf.metrics.true_positives(label_ids,predicted_labels)\n",
    "                true_neg = tf.metrics.true_negatives(label_ids,predicted_labels)   \n",
    "                false_pos = tf.metrics.false_positives(label_ids,predicted_labels)  \n",
    "                false_neg = tf.metrics.false_negatives(label_ids,predicted_labels)\n",
    "                return {\n",
    "                    \"eval_accuracy\": accuracy,\n",
    "                    \"f1_score\": f1_score,\n",
    "                    \"auc\": auc,\n",
    "                    \"precision\": precision,\n",
    "                    \"recall\": recall,\n",
    "                    \"true_positives\": true_pos,\n",
    "                    \"true_negatives\": true_neg,\n",
    "                    \"false_positives\": false_pos,\n",
    "                    \"false_negatives\": false_neg\n",
    "                }\n",
    "\n",
    "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
    "\n",
    "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,loss=loss,train_op=train_op)\n",
    "            else:\n",
    "                return tf.estimator.EstimatorSpec(mode=mode,loss=loss,eval_metric_ops=eval_metrics)\n",
    "        else:\n",
    "            (predicted_labels, log_probs) = create_model(bert_model_hub, is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
    "            predictions = {'probabilities': log_probs,'labels': predicted_labels}\n",
    "            return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Return the actual model function in the closure\n",
    "    return model_fn\n",
    "\n",
    "def estimator_builder(bert_model_hub, OUTPUT_DIR, SAVE_SUMMARY_STEPS, SAVE_CHECKPOINTS_STEPS, label_list, LEARNING_RATE, num_train_steps, num_warmup_steps, BATCH_SIZE):\n",
    "# Specify outpit directory and number of checkpoint steps to save\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        model_dir=OUTPUT_DIR,\n",
    "        save_summary_steps=SAVE_SUMMARY_STEPS,\n",
    "        save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
    "\n",
    "    model_fn = model_fn_builder(\n",
    "      bert_model_hub = bert_model_hub,\n",
    "      num_labels=len(label_list),\n",
    "      learning_rate=LEARNING_RATE,\n",
    "      num_train_steps=num_train_steps,\n",
    "      num_warmup_steps=num_warmup_steps)\n",
    "\n",
    "    estimator = tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      config=run_config,\n",
    "      params={\"batch_size\": BATCH_SIZE})\n",
    "    return estimator, model_fn, run_config\n",
    "\n",
    "\n",
    "def run_on_dfs(train, test, DATA_COLUMN, LABEL_COLUMN, MAX_SEQ_LENGTH = 128,\n",
    "              BATCH_SIZE = 32,\n",
    "              LEARNING_RATE = 2e-5,\n",
    "              NUM_TRAIN_EPOCHS = 3.0,\n",
    "              WARMUP_PROPORTION = 0.1,\n",
    "              SAVE_SUMMARY_STEPS = 100,\n",
    "               SAVE_CHECKPOINTS_STEPS = 10000,\n",
    "              bert_model_hub = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"):\n",
    "\n",
    "    label_list = train[LABEL_COLUMN].unique().tolist()\n",
    "    \n",
    "    tokenizer = create_tokenizer_from_hub_module(bert_model_hub)\n",
    "\n",
    "    train_features = make_features(train, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
    "    test_features = make_features(test, label_list, MAX_SEQ_LENGTH, tokenizer, DATA_COLUMN, LABEL_COLUMN)\n",
    "\n",
    "    num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
    "    num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
    "\n",
    "    estimator, model_fn, run_config = estimator_builder(\n",
    "                                  bert_model_hub, \n",
    "                                  OUTPUT_DIR, \n",
    "                                  SAVE_SUMMARY_STEPS, \n",
    "                                  SAVE_CHECKPOINTS_STEPS, \n",
    "                                  label_list, \n",
    "                                  LEARNING_RATE, \n",
    "                                  num_train_steps, \n",
    "                                  num_warmup_steps, \n",
    "                                  BATCH_SIZE)\n",
    "\n",
    "    train_input_fn = bert.run_classifier.input_fn_builder(\n",
    "        features=train_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=True,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
    "\n",
    "    test_input_fn = run_classifier.input_fn_builder(\n",
    "        features=test_features,\n",
    "        seq_length=MAX_SEQ_LENGTH,\n",
    "        is_training=False,\n",
    "        drop_remainder=False)\n",
    "\n",
    "    result_dict = estimator.evaluate(input_fn=test_input_fn, steps=None)\n",
    "    return result_dict, estimator\n",
    "\n",
    "# #Build combined NN\n",
    "# Seq_NN=bn.create_network(layer_type=(seq['Type'],[Train_seq.shape[1]]+seq['Neuron']),outputlayer_type=seq['Output_type'],optimizer=seq['Optimizer'],Init=seq['InitializationMethod'],vocab=d_to_index,drop_out=seq['Dropout_rate'])\n",
    "# Chem_NN=bn.create_network(layer_type=(chem['Type'],[X_chem.shape[1]]+chem['Neuron']),outputlayer_type=chem['Output_type'],optimizer=chem['Optimizer'],Init=chem['InitializationMethod'])\n",
    "# print(chem['Output_type'],chem['Optimizer'])\n",
    "\n",
    "# \"\"\"Output_modeselection\"\"\"\n",
    "# if chem['Output_type']=='linear_regression':\n",
    "#     if chem['Optimizer'] == 'bgd':\n",
    "#         Chem_NN.compile(loss='mean_squared_error',optimizer= chem['Optimizer'],metrics=[coeff_determination]) # Accuracy performance metric-R2 sgd\n",
    "#     elif chem['Optimizer'] == 'Adam':\n",
    "#         Chem_NN.compile(loss='mean_squared_error',optimizer= chem['Optimizer'],metrics=[coeff_determination]) # Accuracy performance metric-R2 Adam\n",
    "# elif chem['Output_type']=='binary_classifier':\n",
    "#     if chem['Optimizer'] == 'sgd':\n",
    "#         Chem_NN.compile(loss='binary_crossentropy',optimizer= 'sgd',metrics=['accuracy']) # Accuracy performance metric sgd\n",
    "#     elif chem['Optimizer'] == 'Adam':\n",
    "#         Chem_NN.compile(loss='binary_crossentropy',optimizer= 'Adam',metrics=['accuracy']) # Accuracy performance metric Adam\n",
    "# elif chem['Output_type']=='multiple_classifier':\n",
    "#     if chem['Optimizer'] == 'bgd':\n",
    "#         Chem_NN.compile(loss='categorical_crossentropy',optimizer= 'sgd',metrics=['accuracy']) # Accuracy performance metric-R2 sgd\n",
    "#     elif chem['Optimizer'] == 'Adam':\n",
    "#         Chem_NN.compile(loss='categorical_crossentropy',optimizer= 'Adam',metrics=['accuracy']) # Accuracy performance metric-R2 Adam\n",
    "\n",
    "\n",
    "# Chem_NN.fit([X_chem],Y_chem_hardmax,batch_size=chem['Batch_size'], epochs=chem['Epoch'])\n",
    "\n",
    "# # Here we need wo exclude the output layers manually\n",
    "# Chem_NN_new=bn.Model(inputs=Chem_NN.input,outputs=Chem_NN.get_layer('dense_77').output)\n",
    "# combine_model = bn.combine_models(Seq_NN,Train_seq.shape[1],Chem_NN_new,Train_chemical.shape[1],archi=combined['Neuron'])\n",
    "# combine_model.summary()\n",
    "\n",
    "# combine_model.compile(loss='binary_crossentropy',optimizer= 'Adam',metrics=['accuracy'])\n",
    "# c_m=combine_model.fit([Train_seq]+[Train_chemical],Label,batch_size=combined['Batch_size'], epochs=combined['Epoch'],validation_split=0.3)\n",
    "# bn.training_vis(c_m ,\"binary_classifier\",output_path+\"train_dist.svg\")\n",
    "# combine_model.save(output_path+'combined_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
