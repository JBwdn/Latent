{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression with \"deep\" tensor product\n",
    "JLF May 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jean-loup-faulon/anaconda/envs/py35/lib/python3.5/site-packages/matplotlib-2.2.2+828.ga2f65a60e-py3.5-macosx-10.7-x86_64.egg/matplotlib/__init__.py:961: UserWarning: could not find rc file; returning defaults\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas\n",
    "import math\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS TO READ SEQUENCE AND ACTIVITY DATA\n",
    "import Bio\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.inchi import MolFromInchi\n",
    "\n",
    "def getInchi(filename): \n",
    "    # Return a dictonary InChIs{MNX:Inchi,..}\n",
    "    # Change this function if\n",
    "    # ID/name is not in row[0] and InChI not in row[5]\n",
    "    InChIs = {}\n",
    "    with open(filename) as h:\n",
    "        for line in h:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            row = line.rstrip().split('\\t')\n",
    "            mnx = row[0]\n",
    "            InChIs[mnx] = row[5]\n",
    "    return InChIs\n",
    "\n",
    "def fasta_reader(filename):\n",
    "  from Bio.SeqIO.FastaIO import FastaIterator\n",
    "  with open(filename) as handle:\n",
    "    for record in FastaIterator(handle):\n",
    "      yield record\n",
    "\n",
    "def get_seq(ID):\n",
    "    # This function exract sequences from ebi\n",
    "    command  = \"curl -k -X GET --header 'Accept:text/x-fasta' 'https://www.ebi.ac.uk/proteins/api/proteins/\" \n",
    "    command += str(ID) + \"'\"\n",
    "    command += \" > JLF-2018-tmp.fasta\"\n",
    "    os.system(command)\n",
    "    s =\"\"\n",
    "    for entry in fasta_reader(\"JLF-2018-tmp.fasta\"):\n",
    "        s = str(entry.seq)\n",
    "    return s\n",
    "\n",
    "def read_data_file(data_file_name,chem_file_name):\n",
    "    # Change based on the file format must contain\n",
    "    # a chemical id, a sequence id and an activity\n",
    "    # return molecules, sequences and activities\n",
    "    N = 0\n",
    "    EC = {}\n",
    "    ID = {}\n",
    "    CP = {}\n",
    "    RX = {}\n",
    "    KM = {}\n",
    "    MOL = {}\n",
    "    SEQ = {}\n",
    "    InChIs = getInchi(chem_file_name)\n",
    "    with open(data_file_name) as h:\n",
    "        for line in h:\n",
    "            row = line.rstrip().split('\\t')\n",
    "            seq = get_seq(row[1])\n",
    "            mol = None\n",
    "            if row[2] in InChIs:\n",
    "                mol = MolFromInchi(InChIs[row[2]])\n",
    "            if (len(seq) > 0) and (mol is not None): # skip empty entries\n",
    "                EC[N] = row[0]\n",
    "                ID[N] = row[1]\n",
    "                CP[N] = row[2]\n",
    "                RX[N] = row[3]\n",
    "                KM[N] = row[4]\n",
    "                SEQ[N] = seq\n",
    "                MOL[N] = mol\n",
    "                N += 1\n",
    "    return KM, MOL, SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS TO COMPUTE FINGERPRINTS FOR CHEM AND PROTEINS\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "# Get Chemical Fingerprints and k-mers\n",
    "def get_ChemFp(mol,binary):\n",
    "    if binary:\n",
    "        molFp = AllChem.GetMorganFingerprintAsBitVect(mol,2,ChemFpSize)\n",
    "        Fp = [int(x) for x in list(molFp.ToBitString())]\n",
    "    else:\n",
    "        molFp = AllChem.GetHashedMorganFingerprint(mol,2,ChemFpSize)\n",
    "        Fp = list(molFp) \n",
    "    return Fp\n",
    "\n",
    "# k-mers for protein\n",
    "def kmer(sequence,k):\n",
    "    length=len(sequence)\n",
    "    if k>=length:\n",
    "        return # if the kmer size if greater than the lenght of the sequence\n",
    "    stepsize=k-1\n",
    "    i=0\n",
    "    kmers=[]\n",
    "    while i+stepsize<length:\n",
    "        s = sequence[i:i+k]\n",
    "        r = s[::-1]\n",
    "        if r < s:\n",
    "            s = r # only the smalest one\n",
    "        kmers.append(s)\n",
    "        i+=1\n",
    "    return set(kmers)\n",
    "\n",
    "def kmerset(seq,length):\n",
    "    n_seq = len(seq)\n",
    "    if n_seq < 1:\n",
    "        return # no sequences\n",
    "    kmers = kmer(seq[0],length)\n",
    "    for i in range(n_seq):\n",
    "        s = kmer(seq[i],length)\n",
    "        kmers.update(s)\n",
    "        set(kmers)\n",
    "    return(kmers)   \n",
    "\n",
    "# one hot encoding for protein\n",
    "DNA = 'ATCG '\n",
    "PROTEIN = 'ACDEFGHIKLMNPQRSTUVWXY '\n",
    "def seq_2_onehot(seq,alphabet):\n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in seq]\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    return(onehot_encoded)\n",
    "\n",
    "def onehot_2_seq(onehot_encoded,alphabet):\n",
    "    # invert encoding\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    seq = ''\n",
    "    for i in range (0,len(onehot_encoded)):\n",
    "        inverted = int_to_char[np.argmax(onehot_encoded[i])]\n",
    "        seq += str(inverted)\n",
    "    return(seq)\n",
    "\n",
    "# main function to compute fingerprints\n",
    "def get_fingerprint(MOL,SEQ,ChemFpSize,ProtFpSize,\n",
    "                    KmerSize,binary,onehot):\n",
    "    SIZE = len(SEQ)\n",
    "    if onehot:\n",
    "        alphabet = PROTEIN\n",
    "        onehot_dim=len(alphabet) \n",
    "        seqsize=0\n",
    "        for i in range(SIZE):\n",
    "            if len(SEQ[i]) > seqsize:\n",
    "                seqsize= len(SEQ[i])\n",
    "        seqsize = KmerSize*(int(seqsize/KmerSize)+1)\n",
    "        ProtFpSize=int(seqsize*onehot_dim)\n",
    "    else:\n",
    "        onehot_dim = 0\n",
    "        alphabet=kmerset(SEQ,KmerSize)\n",
    "        if ProtFpSize <= 0:\n",
    "            ProtFpSize = len(alphabet)\n",
    "        # hash kmers in alphadic\n",
    "        alphadic={x:randint(0, ProtFpSize-1) for x in alphabet} \n",
    "        \n",
    "    # Get the fingerprint\n",
    "    FP =  np.zeros( (SIZE, ProtFpSize) )\n",
    "    FC =  np.zeros( (SIZE, ChemFpSize) )\n",
    "    for i in range(SIZE):    \n",
    "        FC[i] = get_ChemFp(MOL[i],binary)\n",
    "        if onehot:\n",
    "            s_hot = np.array(seq_2_onehot(SEQ[i],alphabet))\n",
    "            hotsize = s_hot.shape[0]*s_hot.shape[1]\n",
    "            s_hot = s_hot.reshape(hotsize)\n",
    "            s = np.zeros( (ProtFpSize) )\n",
    "            for k in range(hotsize):\n",
    "                s[k] = s_hot[k]\n",
    "            FP[i] = s\n",
    "        else:\n",
    "            for k in alphabet:\n",
    "                FP[i][alphadic[k]] += SEQ[i].count(k)\n",
    "        if binary == False:\n",
    "            FC[i] = normalize(FC[i].reshape(1,-1))\n",
    "            # FP[i] = normalize(FP[i].reshape(1,-1))\n",
    "    return FC, FP, onehot_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DEEP LEARNING MODEL FUNCTIONS\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, LocallyConnected1D\n",
    "from keras.layers import Dropout, MaxPooling1D, Flatten, Merge, RepeatVector\n",
    "from keras.layers import Merge, Lambda, Reshape, multiply, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "def CROP(dimension, start, end):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call x = crop(2,5,10)(x) to slice the second dimension\n",
    "    \n",
    "    def func(x):\n",
    "        if dimension == 0:\n",
    "            return x[start: end]\n",
    "        if dimension == 1:\n",
    "            return x[:, start: end]\n",
    "        if dimension == 2:\n",
    "            return x[:, :, start: end]\n",
    "        if dimension == 3:\n",
    "            return x[:, :, :, start: end]\n",
    "        if dimension == 4:\n",
    "            return x[:, :, :, :, start: end]\n",
    "    return Lambda(func)\n",
    "\n",
    "def CONV(inputs, input_size, latent_size, ouput_size,\n",
    "             strides, filters, dropout, hidden,\n",
    "             activation, loss, optimizer): \n",
    "    out = Reshape((input_size,1)) (inputs) # needed for Conv1D\n",
    "    out = LocallyConnected1D(filters=filters, \n",
    "                 kernel_size=latent_size, strides=strides,\n",
    "                 activation=activation) (out)\n",
    "#    out = Conv1D(filters=filters, \n",
    "#                 kernel_size=latent_size, strides=strides,\n",
    "#                 activation=activation) (out)\n",
    "#    if hidden:\n",
    "#        out = Conv1D(filters=int(filters/10), \n",
    "#                     kernel_size=int(input_size/latent_size),\n",
    "#                     activation=activation) (out)\n",
    "    out = Flatten() (out)    \n",
    "    out = Dropout(dropout) (out)\n",
    "    outputs = Dense(ouput_size, \n",
    "#                    kernel_regularizer = 'l1',\n",
    "                    activation=activation) (out)\n",
    "    return outputs\n",
    "\n",
    "def RNN(inputs, input_size, latent_size, ouput_size,\n",
    "               dropout, hidden, activation, loss, optimizer):   \n",
    "\n",
    "    timesteps=int(input_size/latent_size)\n",
    "    out = Reshape((timesteps,latent_size)) (inputs) # needed for LSTM   \n",
    "    out = LSTM(latent_size,activation=activation, return_sequences=True)(out)\n",
    "    if hidden:\n",
    "        out = LSTM(latent_size,activation=activation, return_sequences=True)(out)\n",
    "    out = Flatten() (out)    \n",
    "    out = Dropout(dropout) (out)\n",
    "    outputs = Dense(ouput_size, \n",
    "#                    kernel_regularizer = 'l1',\n",
    "                    activation=activation) (out)\n",
    "    return outputs\n",
    " \n",
    "\n",
    "\n",
    "def DENSE(inputs, input_size, latent_size, ouput_size,\n",
    "               dropout, hidden, activation, loss, optimizer):   \n",
    "    out = Dense(latent_size, \n",
    "                kernel_regularizer = 'l1',\n",
    "                activation=activation) (inputs)\n",
    "    out = Dropout(dropout) (out)\n",
    "    r = 1\n",
    "    while r <= hidden:\n",
    "        out = Dense(int(latent_size/2**r), \n",
    "#                    kernel_regularizer = 'l1',\n",
    "                    activation=activation) (out)\n",
    "        r += 1    \n",
    "    outputs = Dense(ouput_size, \n",
    "#                    kernel_regularizer = 'l1',\n",
    "                    activation=activation) (out)\n",
    "    return outputs\n",
    "\n",
    "def SEQCHEM(seq_model, che_model,\n",
    "            seq_input_size, che_input_size, \n",
    "            seq_latent_size, che_latent_size, \n",
    "            mix_input_size,strides, filters, \n",
    "            dropout, hidden, activation, loss, optimizer):\n",
    "\n",
    "    # split sequences from chemicals\n",
    "    inputs = Input(shape=((seq_input_size+che_input_size,)))\n",
    "    seq_inputs  = CROP(1,0,seq_input_size) (inputs)\n",
    "    che_inputs = CROP(1,seq_input_size,seq_input_size+che_input_size) (inputs)\n",
    "    # sequence model\n",
    "    if seq_model == 'conv':\n",
    "        seq = CONV(inputs=seq_inputs,\n",
    "                   input_size=seq_input_size, latent_size=seq_latent_size, \n",
    "                   ouput_size=int(mix_input_size/2),\n",
    "                   strides = strides, filters = filters, \n",
    "                   dropout=dropout, hidden=hidden, \n",
    "                   activation=activation, loss=loss, optimizer=optimizer)\n",
    "    elif seq_model == 'dense':\n",
    "        seq = DENSE(inputs=seq_inputs,\n",
    "                    input_size=seq_input_size, latent_size=seq_latent_size,\n",
    "                    ouput_size=int(mix_input_size/2),\n",
    "                    dropout=dropout, hidden=hidden,\n",
    "                    activation=activation, loss=loss, optimizer=optimizer)\n",
    "    elif seq_model == 'rnn':\n",
    "        seq = RNN(inputs=seq_inputs,\n",
    "                    input_size=seq_input_size, latent_size=seq_latent_size,\n",
    "                    ouput_size=int(mix_input_size/2),\n",
    "                    dropout=dropout, hidden=hidden,\n",
    "                    activation=activation, loss=loss, optimizer=optimizer)\n",
    "    # chemical model\n",
    "    if che_model == 'dense':\n",
    "        che = DENSE(inputs=che_inputs,\n",
    "                     input_size=che_input_size, latent_size=che_latent_size, \n",
    "                     ouput_size=int(mix_input_size/2),\n",
    "                     dropout=dropout, hidden=hidden,\n",
    "                     activation=activation, loss=loss, optimizer=optimizer)\n",
    "    elif che_model == 'rnn':\n",
    "        che = RNN(inputs=che_inputs,\n",
    "                     input_size=che_input_size, latent_size=che_latent_size, \n",
    "                     ouput_size=int(mix_input_size/2),\n",
    "                     dropout=dropout, hidden=hidden,\n",
    "                     activation=activation, loss=loss, optimizer=optimizer)\n",
    "\n",
    "    # complete mixed model\n",
    "    out = concatenate([seq, che], axis=-1)\n",
    "    out = Dense(mix_input_size, \n",
    "#                kernel_regularizer = 'l1',\n",
    "                activation=activation) (out)\n",
    "    outputs = Dense(1 ,activation='linear') (out)\n",
    "    tensor = Model(inputs, outputs)\n",
    "    tensor.compile(loss=loss,optimizer=optimizer,metrics=['mse'])\n",
    "    print('Running Tensor model with', tensor.count_params(),'parameters' )\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LOAD DATA (WARNING MAY TAKE A WHILE...)\n",
    "\n",
    "datafile = '2.5.1_unique.tsv' \n",
    "chemfile = 'chem_prop.tsv' # This is the MetaNetX database\n",
    "KM, MOL, SEQ = read_data_file(datafile,chemfile)\n",
    "print(\"Loaded %d sequences, chemicals, and activity values\" % len(SEQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COMPUTE FINGERPRINT \n",
    "# THAT'S WHERE YOU SET UP FINGERPRINT METHODS AND PARAMETERS\n",
    "\n",
    "BINARY = False\n",
    "ONEHOT = False\n",
    "ChemFpSize = 1024\n",
    "# the following 2 parameters are ingored if ONEHOT=True\n",
    "ProtFpSize = 1024 # <= 0 for unfolded fingerprint\n",
    "KMERSIZE = 3 \n",
    "\n",
    "FC, FP, onehot_dim = get_fingerprint(MOL,SEQ,ChemFpSize,ProtFpSize,\n",
    "                                     KMERSIZE,BINARY,ONEHOT)\n",
    "PR =  np.zeros(len(SEQ))\n",
    "for i in range(len(SEQ)):\n",
    "    PR[i]=KM[i]\n",
    "PR = normalize(PR.reshape(1,-1))\n",
    "PR = PR.reshape(len(SEQ))\n",
    "\n",
    "print('SEQ  FP:    ', FP.shape)\n",
    "print('CHEM FP:    ', FC.shape)\n",
    "print('PROP:       ', PR.shape)\n",
    "print('onehot dim: ', onehot_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TRAIN AND EVALUTATE MODEL USING SKLEARN GRID SEARCH\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, ShuffleSplit\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "X = np.concatenate((FP,FC),axis=1) \n",
    "Y = PR\n",
    "print('sequence:',FP.shape,'+','chemical:',FC.shape,'=',X.shape,Y.shape)\n",
    "XFOLD = 5\n",
    "\n",
    "# define the grid search parameters\n",
    "n_iter_search = 4\n",
    "param_grid = dict(seq_model= ['rnn'], # dense, conv (best for onehot encoding), rnn (best for kmers)\n",
    "                  che_model= ['rnn'], # dense, rnn (best)\n",
    "                  seq_input_size= [FP.shape[1]],\n",
    "                  che_input_size = [FC.shape[1]],\n",
    "                  seq_latent_size = [128,256], # for cnn: [9*onehot_dim],\n",
    "                  che_latent_size = [128,256],\n",
    "                  mix_input_size = [8,16,32],\n",
    "                  strides = [0], # for conv: [3*onehot_dim]\n",
    "                  filters = [0], # used only with conv\n",
    "                  dropout = [0.33],\n",
    "                  hidden = [0],\n",
    "                  activation = ['relu','linear'], \n",
    "                  loss = ['mse'],\n",
    "                  optimizer = ['adam'],\n",
    "                  epochs = [100],\n",
    "                  batch_size = [100])\n",
    "\n",
    "# create and train model\n",
    "model = KerasRegressor(build_fn=SEQCHEM, verbose=True)\n",
    "grid  = RandomizedSearchCV(estimator=model, param_distributions=param_grid,n_jobs=1, \n",
    "                           cv=ShuffleSplit(n_splits=5, test_size=1/XFOLD, random_state=0), \n",
    "                           scoring='r2', \n",
    "                           n_iter=n_iter_search)\n",
    "grid_result = grid.fit(X, Y)\n",
    "\n",
    "# summarize results\n",
    "q2m = grid_result.cv_results_['mean_test_score']\n",
    "q2d = grid_result.cv_results_['std_test_score']\n",
    "r2m = grid_result.cv_results_['mean_train_score']\n",
    "r2d = grid_result.cv_results_['std_train_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for i in range(len(params)):\n",
    "    print(\"q2=%.2f(%.2f) r2=%.2f(%.2f) with: %r\" % (q2m[i], q2d[i], r2m[i], r2d[i], params[i]))\n",
    "print(\"Best Q2: %.2f (R2: %.2f) using %s\" % (np.amax(q2m), r2m[np.argmax(q2m)],params[np.argmax(q2m)]))\n",
    "print(\"Best R2: %.2f (Q2: %.2f) using %s\" % (np.amax(r2m), q2m[np.argmax(r2m)],params[np.argmax(r2m)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# GET THE BEST MODEL AND DO SOMETHING WITH IT\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold, train_test_split, KFold, RepeatedKFold\n",
    "from sklearn import datasets, linear_model \n",
    "\n",
    "def get_param(params):\n",
    "    for k in grid_result.best_params_.keys():\n",
    "        if k == 'optimizer':\n",
    "            op = params[k]\n",
    "        elif k == 'epochs':\n",
    "            ep = grid_result.best_params_[k]\n",
    "        elif k == 'hidden':\n",
    "            hi = grid_result.best_params_[k]\n",
    "        elif k == 'batch_size':\n",
    "            bs = grid_result.best_params_[k]\n",
    "        elif k == 'activation':\n",
    "            ac = grid_result.best_params_[k]\n",
    "        elif k == 'loss':\n",
    "            lo = grid_result.best_params_[k]\n",
    "        elif k == 'dropout':\n",
    "            dr = grid_result.best_params_[k]\n",
    "        elif k == 'filters':\n",
    "            fl = grid_result.best_params_[k]\n",
    "        elif k == 'strides':\n",
    "            st = grid_result.best_params_[k]\n",
    "        elif k == 'mix_input_size':\n",
    "            mx = grid_result.best_params_[k]\n",
    "        elif k == 'che_latent_size':\n",
    "            cls = grid_result.best_params_[k]\n",
    "        elif k == 'seq_latent_size':\n",
    "            sls = grid_result.best_params_[k]\n",
    "        elif k == 'che_input_size':\n",
    "            cis = grid_result.best_params_[k]\n",
    "        elif k == 'seq_input_size':\n",
    "            sis = grid_result.best_params_[k]\n",
    "        elif k == 'che_model':\n",
    "            cm = grid_result.best_params_[k]\n",
    "        elif k == 'seq_model':\n",
    "            sm = grid_result.best_params_[k]\n",
    "    return op, ep, hi, bs, ac, lo, dr, fl, st, mx, cls, sls, cis, sis, cm, sm\n",
    "\n",
    "optimizer, epochs, hidden, batch_size, activation, loss, dropout,\\\n",
    "filters, strides, mix_input_size, \\\n",
    "che_latent_size, seq_latent_size, che_input_size,seq_input_size,\\\n",
    "che_model,seq_model =get_param(grid_result.best_params_)\n",
    "\n",
    "XFOLD=10\n",
    "Q2 = np.zeros(XFOLD)\n",
    "R2 = np.zeros(XFOLD)\n",
    "for i in range(XFOLD):\n",
    "    model = SEQCHEM(seq_model, che_model,\n",
    "            seq_input_size, che_input_size, \n",
    "            seq_latent_size, che_latent_size, \n",
    "            mix_input_size,strides, filters, \n",
    "            dropout, hidden, 'linear', loss, optimizer)\n",
    "    X_train, X_valid, Y_train, Y_valid = train_test_split(X, Y, test_size=1/XFOLD, random_state=2*i)\n",
    "    model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "    P = model.predict(X_valid)  \n",
    "    Q2[i]= r2_score(Y_valid,P)\n",
    "    P = model.predict(X_train)  \n",
    "    R2[i]= r2_score(Y_train,P) \n",
    "    print('i = %4d -- Q2: %.4f R2: %.4f' % (i,Q2[i],R2[i]))\n",
    "\n",
    "s = 'Xfold:' + str(XFOLD)\n",
    "s += ' Averaged Q2: %.6f ' % (np.mean(Q2))\n",
    "s += ' (%.6f)' % (np.std(Q2))\n",
    "s += ' Averaged R2: %.4f ' % (np.mean(R2))\n",
    "s += ' (%.4f)' % (np.std(R2))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PLOT (YT= Y predicted) = a * (XT= Y Measured) + b\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "YP = model.predict(X)\n",
    "r2 = r2_score(Y,YP) \n",
    "XT = Y.reshape(len(Y),1)\n",
    "YT = YP.reshape(len(YP),1)\n",
    "\n",
    "print(XT.shape,YT.shape)\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(XT, YT)\n",
    "YP = regr.predict(XT)\n",
    "\n",
    "# Plot outputs\n",
    "plt.scatter(XT, YT,  color='black')\n",
    "plt.plot(XT, YP, color='red', linewidth=1)\n",
    "plt.xlabel('measured')\n",
    "plt.ylabel('predicted')\n",
    "s = 'R2: ' + (\"%.2f\" % r2)\n",
    "plt.title(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "My previous grid search results  \n",
    "No regularization (BINARY)\n",
    "Best R2: 0.79 (Q2: 0.47) using {'seq_input_size': 69897, 'optimizer': 'adam', 'filters': 3, 'dropout': 0.5, 'seq_latent_size': 207, 'hidden': 0, 'che_input_size': 1024, 'epochs': 200, 'strides': 69, 'mix_input_size': 8, 'activation': 'relu', 'loss': 'mse', 'che_latent_size': 64, 'batch_size': 100}\n",
    "\n",
    "Not that stable in Q2...\n",
    "Best R2: 0.79 (Q2: 0.67) using {'seq_latent_size': 207, 'seq_input_size': 69897, 'strides': 69, 'activation': 'relu', 'mix_input_size': 8, 'hidden': 0, 'optimizer': 'adam', 'epochs': 200, 'batch_size': 100, 'loss': 'mse', 'dropout': 0.5, 'filters': 3, 'che_latent_size': 64, 'che_input_size': 1024}\n",
    "\n",
    "Restart\n",
    "Best R2: 0.70 (Q2: 0.40) using {'optimizer': 'adam', 'mix_input_size': 16, 'che_latent_size': 128, 'seq_latent_size': 207, 'dropout': 0.5, 'batch_size': 100, 'filters': 16, 'hidden': 0, 'epochs': 100, 'seq_model': 'conv', 'seq_input_size': 69897, 'che_input_size': 1024, 'strides': 69, 'loss': 'mse', 'activation': 'relu', 'che_model': 'dense'}\n",
    "\n",
    "with regularization (dense)\n",
    "Best R2: 0.69 (Q2: 0.62) using {'seq_latent_size': 207, 'seq_input_size': 69897, 'strides': 69, 'activation': 'relu', 'mix_input_size': 8, 'hidden': 0, 'optimizer': 'adam', 'epochs': 200, 'batch_size': 100, 'loss': 'mse', 'dropout': 0.5, 'filters': 3, 'che_latent_size': 64, 'che_input_size': 1024}\n",
    "\n",
    "My results  (COUNT) \n",
    "Best R2: 0.68 (Q2: 0.22) using {'seq_latent_size': 207, 'seq_input_size': 69897, 'strides': 69, 'activation': 'relu', 'mix_input_size': 8, 'hidden': 0, 'optimizer': 'adam', 'epochs': 200, 'batch_size': 100, 'loss': 'mse', 'dropout': 0.5, 'filters': 3, 'che_latent_size': 64, 'che_input_size': 1024}\n",
    "\n",
    "My results KMERS sequence: (313, 6609) + chemical: (313, 1024) = (313, 7633) (313,)\n",
    "Best R2: 0.65 (Q2: 0.38 (0.55)) using {'batch_size': 100, 'loss': 'mse', 'filters': 3, 'hidden': 0, 'che_latent_size': 64, 'optimizer': 'adam', 'dropout': 0.5, 'seq_latent_size': 1652, 'che_input_size': 1024, 'seq_input_size': 6609, 'strides': 0, 'activation': 'relu', 'mix_input_size': 8, 'epochs': 200}\n",
    "\n",
    "My results LSTM\n",
    "Best R2: 0.78 (Q2: 0.44 (0.36)) using {'optimizer': 'adam', 'mix_input_size': 8, 'che_latent_size': 64, 'seq_latent_size': 207, 'dropout': 0.5, 'batch_size': 100, 'filters': 3, 'hidden': 0, 'epochs': 100, 'seq_model': 'conv', 'seq_input_size': 69897, 'che_input_size': 1024, 'strides': 69, 'loss': 'mse', 'activation': 'relu', 'che_model': 'rnn'}\n",
    "\n",
    "Mixed\n",
    "Best R2: 0.81 (Q2: 0.42) using {'optimizer': 'adam', 'mix_input_size': 8, 'che_latent_size': 128, 'seq_latent_size': 207, 'dropout': 0, 'batch_size': 100, 'filters': 3, 'hidden': 0, 'epochs': 200, 'seq_model': 'conv', 'seq_input_size': 69897, 'che_input_size': 1024, 'strides': 69, 'loss': 'mse', 'activation': 'relu', 'che_model': 'rnn'}\n",
    "Best R2: 0.83 (Q2: 0.18) using {'optimizer': 'adam', 'mix_input_size': 8, 'che_latent_size': 256, 'seq_latent_size': 207, 'dropout': 0.1, 'batch_size': 100, 'filters': 8, 'hidden': 0, 'epochs': 200, 'seq_model': 'conv', 'seq_input_size': 69897, 'che_input_size': 1024, 'strides': 138, 'loss': 'mse', 'activation': 'relu', 'che_model': 'rnn'}\n",
    "Best R2: 0.80 (Q2: 0.58) using {'batch_size': 100, 'seq_model': 'conv', 'che_input_size': 1024, 'mix_input_size': 16, 'hidden': 0, 'seq_input_size': 69897, 'seq_latent_size': 207, 'che_model': 'rnn', 'filters': 12, 'optimizer': 'adam', 'che_latent_size': 256, 'dropout': 0.5, 'strides': 69, 'epochs': 100, 'activation': 'relu', 'loss': 'mse'}\n",
    "\n",
    "Running Tensor model with 3101481 parameters\n",
    "q2=-0.13(0.00) r2=0.07(0.00) with: {'che_latent_size': 256, 'che_input_size': 1024, 'optimizer': 'adam', 'mix_input_size': 8, 'filters': 12, 'epochs': 200, 'dropout': 0.5, 'loss': 'mse', 'batch_size': 100, 'hidden': 0, 'seq_model': 'conv', 'che_model': 'rnn', 'seq_latent_size': 207, 'seq_input_size': 69897, 'strides': 69, 'activation': 'linear'}\n",
    "Best Q2: -0.13 (R2: 0.07) using {'che_latent_size': 256, 'che_input_size': 1024, 'optimizer': 'adam', 'mix_input_size': 8, 'filters': 12, 'epochs': 200, 'dropout': 0.5, 'loss': 'mse', 'batch_size': 100, 'hidden': 0, 'seq_model': 'conv', 'che_model': 'rnn', 'seq_latent_size': 207, 'seq_input_size': 69897, 'strides': 69, 'activation': 'linear'}\n",
    "Best R2: 0.07 (Q2: -0.13) using {'che_latent_size': 256, 'che_input_size': 1024, 'optimizer': 'adam', 'mix_input_size': 8, 'filters': 12, 'epochs': 200, 'dropout': 0.5, 'loss': 'mse', 'batch_size': 100, 'hidden': 0, 'seq_model': 'conv', 'che_model': 'rnn', 'seq_latent_size': 207, 'seq_input_size': 69897, 'strides': 69, 'activation': 'linear'}\n",
    "Best Q2: 0.43 (R2: 0.77) using {'seq_input_size': 69897, 'che_model': 'rnn', 'seq_latent_size': 207, 'dropout': 0.25, 'loss': 'mse', 'filters': 12, 'optimizer': 'adam', 'mix_input_size': 8, 'hidden': 0, 'strides': 69, 'epochs': 200, 'seq_model': 'conv', 'activation': 'relu', 'che_input_size': 1024, 'batch_size': 100, 'che_latent_size': 256}\n",
    "Best Q2: 0.41 (R2: 0.77) using {'seq_input_size': 1024, 'che_model': 'rnn', 'seq_latent_size': 256, 'dropout': 0.33, 'loss': 'mse', 'filters': 8, 'optimizer': 'adam', 'mix_input_size': 8, 'hidden': 0, 'strides': 0, 'epochs': 100, 'seq_model': 'rnn', 'activation': 'relu', 'che_input_size': 1024, 'batch_size': 100, 'che_latent_size': 128}\n",
    "Best R2: 0.79 (Q2: -0.71) using {'optimizer': 'adam', 'activation': 'relu', 'loss': 'mse', 'che_latent_size': 256, 'che_model': 'rnn', 'seq_model': 'rnn', 'che_input_size': 1024, 'epochs': 100, 'seq_latent_size': 256, 'strides': 0, 'filters': 0, 'seq_input_size': 1024, 'dropout': 0.33, 'hidden': 0, 'mix_input_size': 16, 'batch_size': 100}\n",
    "Best R2: 0.95 (Q2: 0.21) using {'batch_size': 100, 'hidden': 0, 'che_input_size': 1024, 'seq_latent_size': 128, 'dropout': 0.33, 'che_latent_size': 256, 'loss': 'mse', 'epochs': 100, 'strides': 0, 'mix_input_size': 32, 'optimizer': 'adam', 'filters': 0, 'activation': 'relu', 'che_model': 'rnn', 'seq_input_size': 1024, 'seq_model': 'rnn'}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
