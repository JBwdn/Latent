{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification with \"deep\" tensor product\n",
    "JLF May 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas\n",
    "import math\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS TO READ SEQUENCE AND ACTIVITY DATA\n",
    "import Bio\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.inchi import MolFromInchi\n",
    "\n",
    "def getInchi(filename): \n",
    "    # Return a dictonary InChIs{MNX:Inchi,..}\n",
    "    # Change this function if\n",
    "    # ID/name is not in row[0] and InChI not in row[5]\n",
    "    InChIs = {}\n",
    "    with open(filename) as h:\n",
    "        for line in h:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            row = line.rstrip().split('\\t')\n",
    "            mnx = row[0]\n",
    "            InChIs[mnx] = row[5]\n",
    "    return InChIs\n",
    "\n",
    "def fasta_reader(filename):\n",
    "  from Bio.SeqIO.FastaIO import FastaIterator\n",
    "  with open(filename) as handle:\n",
    "    for record in FastaIterator(handle):\n",
    "      yield record\n",
    "\n",
    "def get_seq(ID):\n",
    "    # This function exract sequences from ebi\n",
    "    command  = \"curl -k -X GET --header 'Accept:text/x-fasta' 'https://www.ebi.ac.uk/proteins/api/proteins/\" \n",
    "    command += str(ID) + \"'\"\n",
    "    command += \" > JLF-2018-tmp.fasta\"\n",
    "    os.system(command)\n",
    "    s =\"\"\n",
    "    for entry in fasta_reader(\"JLF-2018-tmp.fasta\"):\n",
    "        s = str(entry.seq)\n",
    "    return s\n",
    "\n",
    "def read_data_file(data_file_name,chem_file_name):\n",
    "    # Change based on the file format must contain\n",
    "    # a chemical id, a sequence id and an activity\n",
    "    # return molecules, sequences and activities\n",
    "    N = 0\n",
    "    EC = {}\n",
    "    ID = {}\n",
    "    CP = {}\n",
    "    RX = {}\n",
    "    KM = {}\n",
    "    MOL = {}\n",
    "    SEQ = {}\n",
    "    InChIs = getInchi(chem_file_name)\n",
    "    with open(data_file_name) as h:\n",
    "        for line in h:\n",
    "            row = line.rstrip().split('\\t')\n",
    "            seq = get_seq(row[1])\n",
    "            mol = None\n",
    "            if row[2] in InChIs:\n",
    "                mol = MolFromInchi(InChIs[row[2]])\n",
    "            if (len(seq) > 0) and (mol is not None): # skip empty entries\n",
    "                EC[N] = row[0]\n",
    "                ID[N] = row[1]\n",
    "                CP[N] = row[2]\n",
    "                RX[N] = row[3]\n",
    "                KM[N] = row[4]\n",
    "                SEQ[N] = seq\n",
    "                MOL[N] = mol\n",
    "                N += 1\n",
    "    return KM, MOL, SEQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# FUNCTIONS TO COMPUTE FINGERPRINTS FOR CHEM AND PROTEINS\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "# Get Chemical Fingerprints and k-mers\n",
    "def get_ChemFp(mol,binary):\n",
    "    if binary:\n",
    "        molFp = AllChem.GetMorganFingerprintAsBitVect(mol,2,ChemFpSize)\n",
    "        Fp = [int(x) for x in list(molFp.ToBitString())]\n",
    "    else:\n",
    "        molFp = AllChem.GetHashedMorganFingerprint(mol,2,ChemFpSize)\n",
    "        Fp = list(molFp) \n",
    "    return Fp\n",
    "\n",
    "# k-mers for protein\n",
    "def kmer(sequence,k):\n",
    "    length=len(sequence)\n",
    "    if k>=length:\n",
    "        return # if the kmer size if greater than the lenght of the sequence\n",
    "    stepsize=k-1\n",
    "    i=0\n",
    "    kmers=[]\n",
    "    while i+stepsize<length:\n",
    "        s = sequence[i:i+k]\n",
    "        r = s[::-1]\n",
    "        if r < s:\n",
    "            s = r # only the smalest one\n",
    "        kmers.append(s)\n",
    "        i+=1\n",
    "    return set(kmers)\n",
    "\n",
    "def kmerset(seq,length):\n",
    "    n_seq = len(seq)\n",
    "    if n_seq < 1:\n",
    "        return # no sequences\n",
    "    kmers = kmer(seq[0],length)\n",
    "    for i in range(n_seq):\n",
    "        s = kmer(seq[i],length)\n",
    "        kmers.update(s)\n",
    "        set(kmers)\n",
    "    return(kmers)   \n",
    "\n",
    "# one hot encoding for protein\n",
    "DNA = 'ATCG '\n",
    "PROTEIN = 'ACDEFGHIKLMNPQRSTUVWXY '\n",
    "def seq_2_onehot(seq,alphabet):\n",
    "    # define a mapping of chars to integers\n",
    "    char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "    # integer encode input data\n",
    "    integer_encoded = [char_to_int[char] for char in seq]\n",
    "    # one hot encode\n",
    "    onehot_encoded = list()\n",
    "    for value in integer_encoded:\n",
    "        letter = [0 for _ in range(len(alphabet))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    return(onehot_encoded)\n",
    "\n",
    "def onehot_2_seq(onehot_encoded,alphabet):\n",
    "    # invert encoding\n",
    "    int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "    seq = ''\n",
    "    for i in range (0,len(onehot_encoded)):\n",
    "        inverted = int_to_char[np.argmax(onehot_encoded[i])]\n",
    "        seq += str(inverted)\n",
    "    return(seq)\n",
    "\n",
    "# main function to compute fingerprints\n",
    "def get_fingerprint(MOL,SEQ,ChemFpSize,ProtFpSize,\n",
    "                    KmerSize,binary,onehot):\n",
    "    SIZE = len(SEQ)\n",
    "    if onehot:\n",
    "        alphabet = PROTEIN\n",
    "        onehot_dim=len(alphabet) \n",
    "        seqsize=0\n",
    "        for i in range(SIZE):\n",
    "            if len(SEQ[i]) > seqsize:\n",
    "                seqsize= len(SEQ[i])\n",
    "        seqsize = KmerSize*(int(seqsize/KmerSize)+1)\n",
    "        ProtFpSize=int(seqsize*onehot_dim)\n",
    "    else:\n",
    "        onehot_dim = 0\n",
    "        alphabet=kmerset(SEQ,KmerSize)\n",
    "        if ProtFpSize <= 0:\n",
    "            ProtFpSize = len(alphabet)\n",
    "        # hash kmers in alphadic\n",
    "        alphadic={x:randint(0, ProtFpSize-1) for x in alphabet} \n",
    "        \n",
    "    # Get the fingerprint\n",
    "    FP =  np.zeros( (SIZE, ProtFpSize) )\n",
    "    FC =  np.zeros( (SIZE, ChemFpSize) )\n",
    "    for i in range(SIZE):    \n",
    "        FC[i] = get_ChemFp(MOL[i],binary)\n",
    "        if onehot:\n",
    "            s_hot = np.array(seq_2_onehot(SEQ[i],alphabet))\n",
    "            hotsize = s_hot.shape[0]*s_hot.shape[1]\n",
    "            s_hot = s_hot.reshape(hotsize)\n",
    "            s = np.zeros( (ProtFpSize) )\n",
    "            for k in range(hotsize):\n",
    "                s[k] = s_hot[k]\n",
    "            FP[i] = s\n",
    "        else:\n",
    "            for k in alphabet:\n",
    "                FP[i][alphadic[k]] += SEQ[i].count(k)\n",
    "        if binary == False:\n",
    "            FC[i] = normalize(FC[i].reshape(1,-1))\n",
    "            # FP[i] = normalize(FP[i].reshape(1,-1))\n",
    "    return FC, FP, onehot_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEP LEARNING MODEL FUNCTIONS\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, LSTM, Conv1D, LocallyConnected1D\n",
    "from keras.layers import Dropout, MaxPooling1D, Flatten, Merge, RepeatVector\n",
    "from keras.layers import Merge, Lambda, Reshape, multiply, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "def CROP(dimension, start, end):\n",
    "    # Crops (or slices) a Tensor on a given dimension from start to end\n",
    "    # example : to crop tensor x[:, :, 5:10]\n",
    "    # call x = crop(2,5,10)(x) to slice the second dimension\n",
    "    \n",
    "    def func(x):\n",
    "        if dimension == 0:\n",
    "            return x[start: end]\n",
    "        if dimension == 1:\n",
    "            return x[:, start: end]\n",
    "        if dimension == 2:\n",
    "            return x[:, :, start: end]\n",
    "        if dimension == 3:\n",
    "            return x[:, :, :, start: end]\n",
    "        if dimension == 4:\n",
    "            return x[:, :, :, :, start: end]\n",
    "    return Lambda(func)\n",
    "\n",
    "def CONV(inputs, input_size, latent_size, ouput_size,\n",
    "             strides, filters, dropout, hidden,\n",
    "             activation, loss, optimizer): \n",
    "    out = Reshape((input_size,1)) (inputs) # needed for Conv1D\n",
    "    out = LocallyConnected1D(filters=filters, \n",
    "                 kernel_size=latent_size, strides=strides,\n",
    "                 activation=activation) (out)\n",
    "#    out = Conv1D(filters=filters, \n",
    "#                 kernel_size=latent_size, strides=strides,\n",
    "#                 activation=activation) (out)\n",
    "#    if hidden:\n",
    "#        out = Conv1D(filters=int(filters/10), \n",
    "#                     kernel_size=int(input_size/latent_size),\n",
    "#                     activation=activation) (out)\n",
    "    out = Flatten() (out)    \n",
    "    out = Dropout(dropout) (out)\n",
    "    outputs = Dense(ouput_size, \n",
    "#                    kernel_regularizer = 'l1',\n",
    "                    activation=activation) (out)\n",
    "    return outputs\n",
    "\n",
    "def RNN(inputs, input_size, latent_size, ouput_size,\n",
    "               dropout, hidden, activation, loss, optimizer):   \n",
    "\n",
    "    timesteps=int(input_size/latent_size)\n",
    "    out = Reshape((timesteps,latent_size)) (inputs) # needed for LSTM   \n",
    "    out = LSTM(latent_size,activation=activation, return_sequences=True)(out)\n",
    "    if hidden:\n",
    "        out = LSTM(latent_size,activation=activation, return_sequences=True)(out)\n",
    "    out = Flatten() (out)    \n",
    "    out = Dropout(dropout) (out)\n",
    "    outputs = Dense(ouput_size, \n",
    "#                    kernel_regularizer = 'l1',\n",
    "                    activation=activation) (out)\n",
    "    return outputs\n",
    " \n",
    "\n",
    "\n",
    "def DENSE(inputs, input_size, latent_size, ouput_size,\n",
    "               dropout, hidden, activation, loss, optimizer):   \n",
    "    out = Dense(latent_size, \n",
    "#                kernel_regularizer = 'l1',\n",
    "                activation=activation) (inputs)\n",
    "    out = Dropout(dropout) (out)\n",
    "    r = 1\n",
    "    while r <= hidden:\n",
    "        out = Dense(int(latent_size/2**r), \n",
    "#                    kernel_regularizer = 'l1',\n",
    "                    activation=activation) (out)\n",
    "        r += 1    \n",
    "    outputs = Dense(ouput_size, \n",
    "#                    kernel_regularizer = 'l1',\n",
    "                    activation=activation) (out)\n",
    "    return outputs\n",
    "\n",
    "def SEQCHEM(seq_model, che_model,\n",
    "            seq_input_size, che_input_size, \n",
    "            seq_latent_size, che_latent_size, \n",
    "            mix_input_size,strides, filters, \n",
    "            dropout, hidden, \n",
    "            activation, activation_out, \n",
    "            loss, optimizer, metric):\n",
    "\n",
    "    # split sequences from chemicals\n",
    "    inputs = Input(shape=((seq_input_size+che_input_size,)))\n",
    "    seq_inputs  = CROP(1,0,seq_input_size) (inputs)\n",
    "    che_inputs = CROP(1,seq_input_size,seq_input_size+che_input_size) (inputs)\n",
    "    # sequence model\n",
    "    if seq_model == 'conv':\n",
    "        seq = CONV(inputs=seq_inputs,\n",
    "                   input_size=seq_input_size, latent_size=seq_latent_size, \n",
    "                   ouput_size=int(mix_input_size/2),\n",
    "                   strides = strides, filters = filters, \n",
    "                   dropout=dropout, hidden=hidden, \n",
    "                   activation=activation, loss=loss, optimizer=optimizer)\n",
    "    elif seq_model == 'dense':\n",
    "        seq = DENSE(inputs=seq_inputs,\n",
    "                    input_size=seq_input_size, latent_size=seq_latent_size,\n",
    "                    ouput_size=int(mix_input_size/2),\n",
    "                    dropout=dropout, hidden=hidden,\n",
    "                    activation=activation, loss=loss, optimizer=optimizer)\n",
    "    elif seq_model == 'rnn':\n",
    "        seq = RNN(inputs=seq_inputs,\n",
    "                    input_size=seq_input_size, latent_size=seq_latent_size,\n",
    "                    ouput_size=int(mix_input_size/2),\n",
    "                    dropout=dropout, hidden=hidden,\n",
    "                    activation=activation, loss=loss, optimizer=optimizer)\n",
    "    # chemical model\n",
    "    if che_model == 'dense':\n",
    "        che = DENSE(inputs=che_inputs,\n",
    "                     input_size=che_input_size, latent_size=che_latent_size, \n",
    "                     ouput_size=int(mix_input_size/2),\n",
    "                     dropout=dropout, hidden=hidden,\n",
    "                     activation=activation, loss=loss, optimizer=optimizer)\n",
    "    elif che_model == 'rnn':\n",
    "        che = RNN(inputs=che_inputs,\n",
    "                     input_size=che_input_size, latent_size=che_latent_size, \n",
    "                     ouput_size=int(mix_input_size/2),\n",
    "                     dropout=dropout, hidden=hidden,\n",
    "                     activation=activation, loss=loss, optimizer=optimizer)\n",
    "\n",
    "    # complete mixed model\n",
    "    out = concatenate([seq, che], axis=-1)\n",
    "    out = Dense(mix_input_size, \n",
    "#                kernel_regularizer = 'l1',\n",
    "                activation=activation) (out)\n",
    "    outputs = Dense(1 ,activation=activation_out) (out)\n",
    "    tensor = Model(inputs, outputs)\n",
    "    tensor.compile(loss=loss,optimizer=optimizer,metrics=['accuracy'])\n",
    "    print('Running Tensor model with', tensor.count_params(),'parameters' )\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA (WARNING MAY TAKE A WHILE...)\n",
    "\n",
    "datafile = '2.5.1_classification.tsv' \n",
    "chemfile = 'chem_prop.tsv' # This is the MetaNetX database\n",
    "KM, MOL, SEQ = read_data_file(datafile,chemfile)\n",
    "print(\"Loaded %d sequences, chemicals, and activity values\" % len(SEQ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE FINGERPRINT \n",
    "# THAT'S WHERE YOU SET UP FINGERPRINT METHODS AND PARAMETERS\n",
    "\n",
    "BINARY = False\n",
    "ONEHOT = True\n",
    "ChemFpSize = 1024\n",
    "# the following 2 parameters are ingored if ONEHOT=True\n",
    "ProtFpSize = 2048 # <= 0 for unfolded fingerprint\n",
    "KMERSIZE = 3 \n",
    "\n",
    "FC, FP, onehot_dim = get_fingerprint(MOL,SEQ,ChemFpSize,ProtFpSize,\n",
    "                                     KMERSIZE,BINARY,ONEHOT)\n",
    "print('SEQ  FP:    ', FP.shape)\n",
    "print('CHEM FP:    ', FC.shape)\n",
    "print('onehot dim: ', onehot_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIRECT TRAINING\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "X = np.concatenate((FP,FC),axis=1)\n",
    "Y =  np.zeros(len(SEQ),dtype=int) # classification\n",
    "for i in range(len(SEQ)):\n",
    "    Y[i]=int(KM[i])\n",
    "\n",
    "print('sequence:',FP.shape,'+','chemical:',FC.shape,'=',X.shape,Y.shape)\n",
    "\n",
    "# evaluate model with standardized dataset\n",
    "model = KerasClassifier(build_fn=SEQCHEM, \n",
    "                        seq_model='conv', che_model='rnn',\n",
    "                        seq_input_size=FP.shape[1], che_input_size=FC.shape[1], \n",
    "                        seq_latent_size=9*onehot_dim, che_latent_size=256, \n",
    "                        mix_input_size=8,\n",
    "                        strides=3*onehot_dim, filters=8, \n",
    "                        dropout=0.25, hidden=0, \n",
    "                        activation='relu', activation_out='sigmoid', \n",
    "                        loss='binary_crossentropy', optimizer='adam', \n",
    "                        metric='accuracy',\n",
    "                        epochs=100, batch_size=100, verbose=False)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(model, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
